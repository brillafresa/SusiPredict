# -*- coding: utf-8 -*-
# app.py
# ğŸ“ ìˆ˜ì‹œ í•©ê²© ê°€ëŠ¥ì„± ì˜ˆì¸¡ê¸° (Streamlit)
# v6.2.0 â€” ë””ë²„ê·¸ëª¨ë“œ ë³µì›(ì¤‘ê°„ê³„ì‚° í‘œì‹œ) + ë¡œë²„ìŠ¤íŠ¸ ì•µì»¤ + ê²¹ì¹¨í‘œì‹œ + í™•ë¥ ê¸°ì¤€ ë„ì›€ë§

import numpy as np
import pandas as pd
import math
import json
from typing import Dict, List, Tuple, Optional, NamedTuple

import matplotlib.pyplot as plt
from matplotlib import rcParams
from matplotlib.patches import Patch
from matplotlib.lines import Line2D
from scipy import optimize, stats
from scipy.special import betainc

import streamlit as st

# ===================== í˜ì´ì§€/ìŠ¤íƒ€ì¼ ì„¤ì • =====================
st.set_page_config(page_title="ìˆ˜ì‹œ í•©ê²© ê°€ëŠ¥ì„± ì˜ˆì¸¡ê¸°", layout="wide")

GRADE_BOUNDS = (1.0, 9.0)

# í•œê¸€ í°íŠ¸ (ê°„ë‹¨ ìš°ì„ ìˆœìœ„)
for fam in ["Malgun Gothic", "NanumGothic", "AppleGothic", "Noto Sans CJK KR", "sans-serif"]:
    try:
        plt.rcParams["font.family"] = fam
        break
    except Exception:
        continue
rcParams["axes.unicode_minus"] = False

# ê¸°ë³¸ ê°€ì¤‘ì¹˜
BASE_WEIGHTS = {
    "final_cut": 10.0, "best": 5.0, "median": 5.0, "mean": 4.0, "p70": 3.0,
    "init_mean": 2.0, "init_best": 2.0, "init_worst": 2.0,
    "app_mean": 0.0, "app_best": 0.0, "app_worst": 0.0,
}

# ---- ì»¬ëŸ¼/í‘œì‹œëª… ì •ì˜ ----
COLUMN_CONFIG = {
    "year": "ì…ì‹œí•™ë…„ë„",
    "best": "ìµœì¢…ë“±ë¡ì ìµœê³ ",
    "median": "ìµœì¢…ë“±ë¡ì 50%",
    "p70": "ìµœì¢…ë“±ë¡ì 70%",
    "final_cut": "ìµœì¢…ë“±ë¡ì ìµœì €(ì»·)",
    "mean": "ìµœì¢…ë“±ë¡ì í‰ê· ",
    "init_best": "ìµœì´ˆí•©ê²©ì ìµœê³ ",
    "init_worst": "ìµœì´ˆí•©ê²©ì ìµœì €",
    "init_mean": "ìµœì´ˆí•©ê²©ì í‰ê· ",
    "app_best": "ì§€ì›ì ìµœê³ ",
    "app_worst": "ì§€ì›ì ìµœì €",
    "app_mean": "ì§€ì›ì í‰ê· ",
    "capacity": "ì •ì›",
    "extra": "ì¶”ê°€ì¶©ì›",
    "competition_ratio": "ê²½ìŸë¥ ",
}
COLUMN_ORDER = [
    "year", "best", "median", "p70", "final_cut", "mean",
    "init_best", "init_worst", "init_mean",
    "app_best", "app_worst", "app_mean",
    "capacity", "extra", "competition_ratio"
]
REVERSE_COLUMN_MAP = {v: k for k, v in COLUMN_CONFIG.items()}

# ===================== ìˆ˜í•™ ìœ í‹¸/êµ¬ì¡° =====================
class QuantileTerm(NamedTuple):
    kind: str
    p: float
    value: float

class MeanTerm(NamedTuple):
    kind: str
    value: float
    q_trunc: Optional[float]

def _clip(x, lo, hi): return np.clip(x, lo, hi)
def _safe_ppf_p(p): return _clip(p, 1e-6, 1 - 1e-6)
def _beta_ppf_std(p, a, b): return stats.beta.ppf(_safe_ppf_p(p), a, b)
def _beta_quantile(p, a, b, lo, hi): return _beta_ppf_std(p, a, b) * (hi - lo) + lo
def _beta_cdf(x, a, b, lo, hi): return stats.beta.cdf(_clip((x - lo) / (hi - lo), 0.0, 1.0), a, b)
def _beta_pdf(x, a, b, lo, hi): return stats.beta.pdf(_clip((x - lo) / (hi - lo), 0.0, 1.0), a, b) / (hi - lo)

def _beta_trunc_mean_std(a, b, z_trunc):
    denominator = betainc(a, b, z_trunc)
    if denominator <= 1e-12:
        return z_trunc * 0.5
    numerator = (a / (a + b)) * betainc(a + 1, b, z_trunc)
    return numerator / denominator

def _admitted_quantile_from_underlying(p_cond, a, b, lo, hi, q_sel):
    return _beta_quantile(p_cond * q_sel, a, b, lo, hi)

def _is_bad(a, b):
    return not (np.isfinite(a) and np.isfinite(b) and 0.2 < a < 100.0 and 0.2 < b < 100.0)

# ğŸ†• ì²´í¬ë°•ìŠ¤ í•´ì œ ì‹œ ê°’ì„ ë¦¬ì…‹í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
def _reset_value_on_uncheck(checkbox_key: str, value_key: str, default_value):
    """ì²´í¬ë°•ìŠ¤ê°€ í•´ì œë˜ì—ˆì„ ë•Œ í•´ë‹¹ ê°’ í•„ë“œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ë¦¬ì…‹í•©ë‹ˆë‹¤."""
    if not st.session_state.get(checkbox_key, False):
        st.session_state[value_key] = default_value

def _solve_beta_two_quantiles(q1: QuantileTerm, q2: QuantileTerm, lo, hi, init_ab=(3.0, 6.0)):
    def objective(v):
        a, b = math.exp(v[0]), math.exp(v[1])
        e1 = _beta_quantile(q1.p, a, b, lo, hi) - q1.value
        e2 = _beta_quantile(q2.p, a, b, lo, hi) - q2.value
        return e1*e1 + e2*e2
    try:
        res = optimize.minimize(objective, np.log(np.array(init_ab)), method="Nelder-Mead")
        ab = np.exp(res.x)
        if not np.all(np.isfinite(ab)):
            return init_ab
        return float(ab[0]), float(ab[1])
    except Exception:
        return init_ab

def _get_stochastic_forecast(years, values, x_new, n_scenarios, min_val=0.0):
    valid_mask = np.isfinite(years) & np.isfinite(values)
    years, values = years[valid_mask], values[valid_mask]
    if len(values) < 4:
        return np.random.choice(values, n_scenarios, replace=True) if len(values) > 0 else np.array([])
    slope, intercept, _, _ = stats.theilslopes(values, years)
    forecast_center = intercept + slope * x_new
    predicted_values = intercept + slope * years
    residuals = values - predicted_values
    scenarios = forecast_center + np.random.choice(residuals, n_scenarios, replace=True)
    return np.maximum(min_val, scenarios)

# ===================== ì „ì²˜ë¦¬/í”¼íŒ…/íˆ¬ì˜ =====================
def prepare_years(df_input: List[Dict]) -> pd.DataFrame:
    """ê³¼ê±° ë°ì´í„° ê°€ê³µ + ìœ íš¨ ê²½ìŸë¥  ë³´ì •(ì§€ì›ì í‰ê·  ê¸°ë°˜) + q_select ê³„ì‚°
       ê²½ìŸë¥  ì •ì˜: ratio = applicants / capacity
    """
    if not df_input:
        return pd.DataFrame()
    df_temp = pd.DataFrame(df_input)

    valid_app_means = df_temp['app_mean'].dropna()
    baseline_app_mean = valid_app_means.mean() if len(valid_app_means) >= 2 else None

    rows = []
    for r in df_input:
        cap = r.get("capacity", None)
        ext = r.get("extra", None)
        cap = int(cap) if cap is not None else None
        ext = int(ext) if ext is not None else 0
        total = (cap or 0) + (ext or 0)  # ìµœì¢… ì„ ë°œ ì¸ì› N

        ratio = r.get("competition_ratio", None)  # ratio = applicants / capacity
        applicants = r.get("applicants", None)
        if ratio is None and applicants is not None and cap:
            try:
                ratio = float(applicants) / float(cap) if cap > 0 else None
            except Exception:
                ratio = None

        effective_ratio = ratio
        if (ratio is not None) and (baseline_app_mean is not None) and pd.notnull(r.get("app_mean")):
            deviation = (r["app_mean"] - baseline_app_mean) / baseline_app_mean
            effective_ratio = ratio * (1 + np.clip(deviation, -0.3, 0.3))

        M = None
        if effective_ratio is not None and cap:
            M = float(effective_ratio) * float(cap)

        q_sel = min(1.0, float(total) / float(M)) if (M and M > 0) else None

        row_data = r.copy()
        row_data.update({
            "total_seats": total if total > 0 else None,      # N
            "competition_ratio": ratio,                        # ratio = applicants / capacity
            "effective_competition_ratio": effective_ratio,    # ë³´ì • ê²½ìŸë¥ 
            "q_select": q_sel,                                 # N/M
        })
        rows.append(row_data)

    return pd.DataFrame(rows).sort_values("year").reset_index(drop=True)

def _objective_function(params, quantile_terms, mean_terms, lo, hi, weights):
    a, b = math.exp(params[0]), math.exp(params[1])
    loss = 0.0
    for term in quantile_terms:
        pred = _beta_quantile(term.p, a, b, lo, hi)
        w = weights.get(term.kind, 1.0)
        if w > 0:
            loss += w * (pred - term.value)**2
    for term in mean_terms:
        w = weights.get(term.kind, 1.0)
        if w == 0:
            continue
        if term.q_trunc is None:
            pred = lo + (hi - lo) * (a / (a + b))
        else:
            z_trunc = _beta_ppf_std(term.q_trunc, a, b)
            mean_std = _beta_trunc_mean_std(a, b, z_trunc)
            pred = lo + (hi - lo) * mean_std
        loss += w * (pred - term.value)**2
    return loss

def _fit_underlying_from_competitive(row, lo, hi, weights):
    """ê²½ìŸë¥ /ì¶©ì› ì •ë³´ê°€ ìˆëŠ” ì—°ë„: ì „ì²´ ì§€ì›ìë¶„í¬(Beta) ì—­ì¶”ì •"""
    q_sel = row["q_select"]
    total, cap = row["total_seats"], row["capacity"]  # total=N, cap=ì •ì›
    eff_ratio = row.get("effective_competition_ratio", None)

    M = int(round(eff_ratio * cap)) if (eff_ratio is not None and cap) else None
    q_init = (cap / M) if (cap and M and M > 0) else None

    q_terms: List[QuantileTerm] = []
    m_terms: List[MeanTerm] = []

    if pd.notnull(row.get("median")):
        q_terms.append(QuantileTerm("median", 0.5 * q_sel, row["median"]))
    if pd.notnull(row.get("p70")):
        q_terms.append(QuantileTerm("p70", 0.7 * q_sel, row["p70"]))
    if pd.notnull(row.get("final_cut")):
        q_terms.append(QuantileTerm("final_cut", 1.0 * q_sel, row["final_cut"]))
    if pd.notnull(row.get("best")) and total:
        q_terms.append(QuantileTerm("best", (1/(total+1)) * q_sel, row["best"]))
    if pd.notnull(row.get("mean")):
        m_terms.append(MeanTerm("mean", row["mean"], q_sel))

    if q_init and cap:
        if pd.notnull(row.get("init_best")):
            q_terms.append(QuantileTerm("init_best", (1/(cap+1)) * q_init, row["init_best"]))
        if pd.notnull(row.get("init_worst")):
            q_terms.append(QuantileTerm("init_worst", (cap/(cap+1)) * q_init, row["init_worst"]))
        if pd.notnull(row.get("init_mean")):
            m_terms.append(MeanTerm("init_mean", row["init_mean"], q_init))

    if M:
        if pd.notnull(row.get("app_best")):
            q_terms.append(QuantileTerm("app_best", 1/(M+1), row["app_best"]))
        if pd.notnull(row.get("app_worst")):
            q_terms.append(QuantileTerm("app_worst", M/(M+1), row["app_worst"]))
        if pd.notnull(row.get("app_mean")):
            m_terms.append(MeanTerm("app_mean", row["app_mean"], None))

    if len(q_terms) < 2:
        return 3.0, 6.0, np.nan, {"M": M, "q_init": q_init}

    q_terms.sort(key=lambda t: t.p)
    init_a, init_b = _solve_beta_two_quantiles(q_terms[0], q_terms[-1], lo, hi)

    res = optimize.minimize(
        _objective_function,
        np.log([init_a, init_b]),
        args=(q_terms, m_terms, lo, hi, weights),
        method="Nelder-Mead",
        options={"maxiter": 2500}
    )
    a, b = np.exp(res.x)
    if (not res.success) or _is_bad(a, b):
        return 3.0, 6.0, res.fun if hasattr(res, "fun") else np.nan, {"M": M, "q_init": q_init}
    return float(a), float(b), float(res.fun), {"M": M, "q_init": q_init}

def _fit_admitted_without_ratio(row, lo, hi, weights):
    """ê²½ìŸë¥  ì •ë³´ê°€ ì—†ëŠ” ì—°ë„: í•©ê²©ì ë¶„í¬ë¡œ ê°€ì •í•˜ì—¬ í”¼íŒ…(ê·¼ì‚¬)"""
    N, cap = row["total_seats"], row["capacity"]
    q_terms: List[QuantileTerm] = []
    m_terms: List[MeanTerm] = []

    if pd.notnull(row.get("median")):
        q_terms.append(QuantileTerm("median", 0.5, row["median"]))
    if pd.notnull(row.get("p70")):
        q_terms.append(QuantileTerm("p70", 0.7, row["p70"]))
    if pd.notnull(row.get("final_cut")) and N:
        q_terms.append(QuantileTerm("final_cut", N/(N+1), row["final_cut"]))
    if pd.notnull(row.get("best")) and N:
        q_terms.append(QuantileTerm("best", 1/(N+1), row["best"]))
    if pd.notnull(row.get("mean")):
        m_terms.append(MeanTerm("mean", row["mean"], None))

    if cap and N and N > 0:
        phi = cap / float(N)
        if pd.notnull(row.get("init_best")):
            q_terms.append(QuantileTerm("init_best", (1/(cap+1))*phi, row["init_best"]))
        if pd.notnull(row.get("init_worst")):
            q_terms.append(QuantileTerm("init_worst", (cap/(cap+1))*phi, row["init_worst"]))
        if pd.notnull(row.get("init_mean")):
            m_terms.append(MeanTerm("init_mean", row["init_mean"], phi))

    if len(q_terms) < 2:
        return 3.0, 6.0, np.nan, {}

    q_terms.sort(key=lambda t: t.p)
    init_a, init_b = _solve_beta_two_quantiles(q_terms[0], q_terms[-1], lo, hi)

    res = optimize.minimize(
        _objective_function,
        np.log([init_a, init_b]),
        args=(q_terms, m_terms, lo, hi, weights),
        method="Nelder-Mead",
        options={"maxiter": 2500}
    )
    a, b = np.exp(res.x)
    if (not res.success) or _is_bad(a, b):
        return 3.0, 6.0, res.fun if hasattr(res, "fun") else np.nan, {}
    return float(a), float(b), float(res.fun), {}

def fit_per_year_models(df, lo, hi, weights, anchor_tol: float = 0.75):
    """ì—°ë„ë³„ (a,b) í”¼íŒ… + ì£¼ìš” ì§€í‘œì˜ ì í•©ì¹˜ ê³„ì‚° + ë¡œë²„ìŠ¤íŠ¸ ì•µì»¤ ìƒì„±"""
    def choose_anchor(input_val, fitted_val, tol=anchor_tol):
        iv_ok = (input_val is not None) and pd.notnull(input_val)
        fv_ok = (fitted_val is not None) and pd.notnull(fitted_val)
        if iv_ok and fv_ok:
            return float(input_val) if abs(float(fitted_val) - float(input_val)) > tol else float(fitted_val)
        elif iv_ok:
            return float(input_val)
        elif fv_ok:
            return float(fitted_val)
        else:
            return np.nan

    cols = [
        "year","beta_a","beta_b","model_type","fit_loss","q_select","total_seats","capacity",
        "fitted_median","fitted_p70","fitted_final","fitted_best","fitted_final_mean",
        "fitted_init_best","fitted_init_worst","fitted_init_mean",
        "fitted_app_best","fitted_app_worst","fitted_app_mean",
        # robust anchors
        "anchor_median","anchor_p70","anchor_final","anchor_best",
        "anchor_init_best","anchor_init_worst","anchor_final_mean","anchor_init_mean","anchor_app_mean"
    ]
    outs = []
    for _, row in df.iterrows():
        row_dict = row.to_dict()
        if pd.notnull(row["q_select"]):
            a, b, loss, meta = _fit_underlying_from_competitive(row_dict, lo, hi, weights)
            q_sel = float(row["q_select"])
            total = int(row["total_seats"]) if row["total_seats"] else None
            cap = int(row["capacity"]) if row["capacity"] else None
            M = meta.get("M", None)
            q_init = meta.get("q_init", None)

            med = _admitted_quantile_from_underlying(0.5, a, b, lo, hi, q_sel)
            p70 = _admitted_quantile_from_underlying(0.7, a, b, lo, hi, q_sel)
            fin = _admitted_quantile_from_underlying(1.0, a, b, lo, hi, q_sel)
            bst = _admitted_quantile_from_underlying(1.0/(total+1.0), a, b, lo, hi, q_sel) if total else np.nan

            z = _beta_ppf_std(q_sel, a, b)
            fm = lo + (hi - lo) * _beta_trunc_mean_std(a, b, z)

            if q_init is not None and cap:
                init_b = _admitted_quantile_from_underlying(1.0/(cap+1.0), a, b, lo, hi, q_init)
                init_w = _admitted_quantile_from_underlying(cap/(cap+1.0), a, b, lo, hi, q_init)
                z0 = _beta_ppf_std(q_init, a, b)
                im = lo + (hi - lo) * _beta_trunc_mean_std(a, b, z0)
            else:
                init_b = init_w = im = np.nan

            if M:
                app_b = _beta_quantile(1.0/(M+1.0), a, b, lo, hi)
                app_w = _beta_quantile(M/(M+1.0), a, b, lo, hi)
                app_m = lo + (hi - lo) * (a/(a+b))
            else:
                app_b = app_w = app_m = np.nan

            # anchors (robust)
            anc_median = choose_anchor(row.get("median"), med)
            anc_p70    = choose_anchor(row.get("p70"), p70)
            anc_final  = choose_anchor(row.get("final_cut"), fin)
            anc_best   = choose_anchor(row.get("best"), bst)
            anc_ibest  = choose_anchor(row.get("init_best"), init_b)
            anc_iworst = choose_anchor(row.get("init_worst"), init_w)
            anc_fmean  = fm  # ì…ë ¥ì¹˜ ì—†ìŒ â†’ fitted ì‚¬ìš©
            anc_imean  = choose_anchor(row.get("init_mean"), im)
            anc_amean  = choose_anchor(row.get("app_mean"), app_m)

            outs.append([
                row["year"], a, b, "underlying+trunc", loss, q_sel,
                row["total_seats"], row["capacity"],
                med, p70, fin, bst, fm,
                init_b, init_w, im,
                app_b, app_w, app_m,
                anc_median, anc_p70, anc_final, anc_best,
                anc_ibest, anc_iworst, anc_fmean, anc_imean, anc_amean
            ])
        else:
            a, b, loss, _ = _fit_admitted_without_ratio(row_dict, lo, hi, weights)
            N = int(row["total_seats"]) if row["total_seats"] else None
            cap = int(row["capacity"]) if row["capacity"] else None

            med = _beta_quantile(0.5, a, b, lo, hi)
            p70 = _beta_quantile(0.7, a, b, lo, hi)
            fin = _beta_quantile(N/(N+1.0), a, b, lo, hi) if N else np.nan
            bst = _beta_quantile(1.0/(N+1.0), a, b, lo, hi) if N else np.nan
            fm  = lo + (hi - lo) * (a/(a+b))

            if cap and N and N > 0:
                phi = cap / float(N)
                init_b = _beta_quantile((1.0/(cap+1.0)) * phi, a, b, lo, hi)
                init_w = _beta_quantile((cap/(cap+1.0)) * phi, a, b, lo, hi)
                z_phi = _beta_ppf_std(phi, a, b)
                im = lo + (hi - lo) * _beta_trunc_mean_std(a, b, z_phi)
            else:
                init_b = init_w = im = np.nan

            # anchors (robust)
            anc_median = choose_anchor(row.get("median"), med)
            anc_p70    = choose_anchor(row.get("p70"), p70)
            anc_final  = choose_anchor(row.get("final_cut"), fin)
            anc_best   = choose_anchor(row.get("best"), bst)
            anc_ibest  = choose_anchor(row.get("init_best"), init_b)
            anc_iworst = choose_anchor(row.get("init_worst"), init_w)
            anc_fmean  = fm
            anc_imean  = choose_anchor(row.get("init_mean"), im)
            anc_amean  = choose_anchor(row.get("app_mean"), np.nan)

            outs.append([
                row["year"], a, b, "admitted-only", loss, np.nan,
                row["total_seats"], row["capacity"],
                med, p70, fin, bst, fm,
                init_b, init_w, im,
                np.nan, np.nan, np.nan,
                anc_median, anc_p70, anc_final, anc_best,
                anc_ibest, anc_iworst, anc_fmean, anc_imean, anc_amean
            ])

    return pd.DataFrame(outs, columns=cols).sort_values("year").reset_index(drop=True)

# ---- ìµœê·¼ì—°ë„ ê°€ì¤‘ íšŒê·€ë¡œ 1ë…„ í›„ ì§€í‘œ ì•µì»¤ ì˜ˆì¸¡ ----
def _recency_weighted_forecast(years: np.ndarray, values: np.ndarray, x_new: float,
                               half_life: float = 1.0, mix: float = 0.65) -> float:
    if len(values) == 0:
        return np.nan
    if len(values) == 1:
        return float(values[-1])

    y_last = float(values[-1])
    t_last = float(years[-1])

    w = 0.5 ** ((t_last - years) / float(half_life))
    w = np.clip(w, 1e-6, 1.0)

    S_w  = np.sum(w)
    S_x  = np.sum(w * years)
    S_y  = np.sum(w * values)
    S_xx = np.sum(w * years * years)
    S_xy = np.sum(w * years * values)
    denom = (S_w * S_xx - S_x * S_x)
    if abs(denom) < 1e-12:
        y_hat = y_last
    else:
        a = (S_w * S_xy - S_x * S_y) / denom
        b = (S_y - a * S_x) / S_w
        y_hat = a * x_new + b

    return float(mix * y_hat + (1.0 - mix) * y_last)

def project_current_year(
    df, df_fit, lo, hi,
    capacity_this_year, extra_this_year, ratio_this_year, weights
):
    """ì˜¬í•´ ì§€ì›ì ë¶„í¬(Beta) ì‚°ì¶œ: ratioëŠ” ì •ì›(capacity) ê¸°ì¤€"""
    years = df_fit["year"].values.astype(float)
    current_year = years.max() + 1.0 if len(years) > 0 else 2026

    cap = int(capacity_this_year or 0)
    if cap <= 0:
        raise ValueError("ì˜¬í•´ ì •ì›ì€ 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    total_seats_base = cap + (int(extra_this_year) if extra_this_year is not None else 0)

    # ratio = applicants / capacity (ê²½ìŸë¥ ë§Œ ì‚¬ìš©)
    ratio = ratio_this_year if ratio_this_year and ratio_this_year > 0 else None

    ratio_for_projection = ratio
    if ratio_for_projection is None:
        historical = df["competition_ratio"].dropna().values
        ratio_for_projection = np.median(historical) if len(historical) > 0 else None

    M = int(round(ratio_for_projection * cap)) if (ratio_for_projection and cap > 0) else None
    q_sel = (min(1.0, total_seats_base / M) if (M and M > 0) else None)
    q_init = (cap / float(M)) if (cap and M and M > 0) else None

    # --- ì•µì»¤ëŠ” 'robust anchor' ì—´ì„ ì‚¬ìš© ---
    def _ts(name):
        s = df_fit[[name, "year"]].dropna()
        if s.empty:
            return None
        return _recency_weighted_forecast(
            s["year"].values.astype(float),
            s[name].values.astype(float),
            current_year,
            half_life=1.0,   # ìµœê·¼ 1ë…„ ë°˜ê°
            mix=0.65         # íšŒê·€ì˜ˆì¸¡ 65% + ì§ì „ê°’ 35%
        )

    q_terms: List[QuantileTerm] = []
    m_terms: List[MeanTerm] = []
    anchors_map = {
        "median": ("anchor_median", 0.5),
        "p70": ("anchor_p70", 0.7),
        "final_cut": ("anchor_final", 1.0),
        "best": ("anchor_best", 1.0/(total_seats_base+1)),
        "init_best": ("anchor_init_best", 1.0/(cap+1) if cap else 0),
        "init_worst": ("anchor_init_worst", cap/(cap+1) if cap else 1),
    }
    for kind, (col, p_cond) in anchors_map.items():
        v = _ts(col)
        if v is None or p_cond == 0:
            continue
        if kind.startswith("init") and q_init:
            q_terms.append(QuantileTerm(kind, p_cond * q_init, v))
        else:
            p = p_cond * q_sel if q_sel else p_cond
            q_terms.append(QuantileTerm(kind, p, v))

    if (v := _ts("anchor_final_mean")) is not None:
        m_terms.append(MeanTerm("mean", v, q_sel))
    if (v := _ts("anchor_app_mean")) is not None and M:
        m_terms.append(MeanTerm("app_mean", v, None))
    if (v := _ts("anchor_init_mean")) is not None and q_init:
        m_terms.append(MeanTerm("init_mean", v, q_init))

    if len(q_terms) < 2:
        a0, b0 = 3.0, 6.0
    else:
        q_terms.sort(key=lambda x: x.p)
        a0, b0 = _solve_beta_two_quantiles(q_terms[0], q_terms[-1], lo, hi)

    res = optimize.minimize(
        _objective_function,
        np.log([a0, b0]),
        args=(q_terms, m_terms, lo, hi, weights),
        method="Nelder-Mead",
        options={"maxiter": 2500}
    )
    a, b = np.exp(res.x)
    if (not res.success) or _is_bad(a, b):
        a, b = 3.0, 6.0

    return {
        "a": float(a), "b": float(b),
        "model_type": "underlying+trunc" if q_sel else "admitted-only",
        "q_select_this": q_sel,
        "total_seats_this": total_seats_base,  # N
        "capacity_this": cap,                   # ì •ì›
        "ratio_this": ratio,                    # ratio = applicants/capacity
        "M_this": M,                            # ì§€ì›ììˆ˜
        "q_init_this": q_init
    }

# ===================== ì‹œë®¬ë ˆì´ì…˜ =====================
def simulate_acceptance(
    proj, df, applicant_grade, lo, hi,
    capacity_this_year: int,
    extra_this_year: Optional[int],
    ratio_this_year: Optional[float],
    n_scenarios=5000
):
    a, b = proj["a"], proj["b"]
    is_ratio_known = ratio_this_year is not None and ratio_this_year > 0.0
    is_extra_known = extra_this_year is not None

    years = df["year"].values.astype(float)
    current_year = years.max() + 1.0 if len(years) > 0 else 2026

    extra_ratios = np.array([])

    if is_ratio_known:
        ratios = np.full(n_scenarios, float(ratio_this_year))
    else:
        ratios = _get_stochastic_forecast(
            years, df["competition_ratio"].values, current_year, n_scenarios, min_val=0.5
        )

    if is_extra_known:
        extras = np.full(n_scenarios, int(extra_this_year))
    else:
        with np.errstate(divide='ignore', invalid='ignore'):
            cap_series = pd.to_numeric(df["capacity"], errors="coerce").astype(float)
            extra_series = pd.to_numeric(df["extra"], errors="coerce").astype(float)
            extra_ratio_series = np.where(
                (cap_series > 0) & np.isfinite(cap_series),
                np.nan_to_num(extra_series / cap_series, nan=0.0),
                np.nan
            )
        extra_ratios = _get_stochastic_forecast(
            years, extra_ratio_series, current_year, n_scenarios, min_val=0.0
        )
        extras = np.round(np.nan_to_num(extra_ratios, nan=0.0) * capacity_this_year).astype(int)

    N_scenarios = capacity_this_year + extras                        # N
    M_scenarios = np.round(ratios * capacity_this_year).astype(int)  # M = ratio * capacity

    valid_mask = (N_scenarios > 0) & (M_scenarios >= N_scenarios)
    if not np.any(valid_mask):
        Ts = _beta_quantile(0.999, a, b, lo, hi) * np.ones(n_scenarios)
        accepted = (Ts >= applicant_grade)
        k, n = int(np.sum(accepted)), int(len(accepted))
        from scipy.stats import beta as _beta
        p_accept = k / n if n > 0 else np.nan
        p_accept_ci = tuple(_beta.ppf([0.05, 0.95], k + 0.5, (n - k) + 0.5)) if n > 0 else (np.nan, np.nan)
        return {"mode":"underfilled","Ts":Ts,"p_accept":p_accept,"p_accept_ci":p_accept_ci,
                "p_pct":np.nan,"p_pct_ci":(np.nan,np.nan)}

    N_scenarios = N_scenarios[valid_mask]
    M_scenarios = M_scenarios[valid_mask]

    U_samples = stats.beta.rvs(N_scenarios, M_scenarios - N_scenarios + 1)
    Ts = _beta_quantile(U_samples, a, b, lo, hi)

    accepted_mask = (Ts >= applicant_grade)
    k, n = int(np.sum(accepted_mask)), int(len(accepted_mask))
    from scipy.stats import beta as _beta
    p_accept = k / n if n > 0 else np.nan
    p_accept_ci = tuple(_beta.ppf([0.05, 0.95], k + 0.5, (n - k) + 0.5)) if n > 0 else (np.nan, np.nan)

    Fg = _beta_cdf(applicant_grade, a, b, lo, hi)
    if k > 0:
        ranks = np.clip(Fg / np.maximum(U_samples[accepted_mask], 1e-9), 0.0, 1.0)
        p_pct = float(np.mean(ranks))
        p_pct_ci = tuple(np.quantile(ranks, [0.05, 0.95]))
    else:
        p_pct, p_pct_ci = np.nan, (np.nan, np.nan)

    out = {
        "mode": "probabilistic",
        "Ts": Ts[np.isfinite(Ts)],
        "p_accept": p_accept,
        "p_accept_ci": p_accept_ci,
        "p_pct": p_pct,
        "p_pct_ci": p_pct_ci,
    }
    if ratio_this_year is None and len(ratios) > 0:
        out["forecasted_ratio_median"] = float(np.median(ratios))
        out["forecasted_ratio_ci"] = tuple(np.quantile(ratios, [0.05, 0.95]))
    if extra_this_year is None and len(extra_ratios) > 0:
        out["forecasted_extra_rate_median"] = float(np.median(extra_ratios))
        out["forecasted_extra_rate_ci"] = tuple(np.quantile(extra_ratios, [0.05, 0.95]))
    return out

# ===================== íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ & ì‹œê°í™” =====================
def run_pipeline(
    years_data, department_name, applicant_grade,
    grade_bounds=(1.0, 9.0),
    capacity_this_year=None, extra_this_year=None,
    ratio_this_year=None,
    n_scenarios=5000, weights=BASE_WEIGHTS, debug=False
):
    lo, hi = grade_bounds

    df = prepare_years(years_data)
    df_fit = fit_per_year_models(df, lo, hi, weights)
    proj = project_current_year(
        df, df_fit, lo, hi,
        capacity_this_year, extra_this_year,
        ratio_this_year, weights
    )
    sim = simulate_acceptance(
        proj, df, applicant_grade, lo, hi,
        capacity_this_year=int(capacity_this_year),
        extra_this_year=int(extra_this_year) if extra_this_year is not None else None,
        ratio_this_year=proj.get("ratio_this"),
        n_scenarios=n_scenarios
    )

    # ---------- ë””ë²„ê·¸ íŒ¨ë„ ----------
    if debug:
        st.markdown("### ğŸ§© ë””ë²„ê·¸ íŒ¨ë„")

        # ì „ì²˜ë¦¬ í•µì‹¬ ì§€í‘œ
        dbg_pre = pd.DataFrame({
            "year": df["year"],
            "capacity": df["capacity"],
            "extra": df["extra"],
            "ratio(raw)": df["competition_ratio"],
            "ratio(effective)": df["effective_competition_ratio"],
            "total_seats(N)": df["total_seats"],
            "q_select(N/M)": df["q_select"],
            "M(=ratio*capacity)": np.where(
                pd.notnull(df["effective_competition_ratio"]) & pd.notnull(df["capacity"]),
                df["effective_competition_ratio"] * df["capacity"], np.nan
            ),
        })
        st.code("ğŸ§© ì „ì²˜ë¦¬ ê²°ê³¼ (q_select Â· ëª¨ì§‘/ì§€ì› ê·œëª¨)", language="text")
        st.dataframe(dbg_pre, use_container_width=True)

        # í”¼íŒ… ê²°ê³¼(ì…ë ¥ vs ì í•©ì¹˜ vs ì•µì»¤)
        cols_show = [
            "year","beta_a","beta_b","model_type","fit_loss","q_select",
            "fitted_best","fitted_final","fitted_median","fitted_p70","fitted_final_mean",
            "anchor_best","anchor_final","anchor_median","anchor_p70","anchor_final_mean"
        ]
        st.code("ğŸ§ª ì—°ë„ë³„ í”¼íŒ… ê²°ê³¼ (ì…ë ¥ vs ì í•©ì¹˜ Â· ì•µì»¤)", language="text")
        st.dataframe(df_fit[cols_show], use_container_width=True)

        # ì˜¬í•´ íˆ¬ì˜ íŒŒë¼ë¯¸í„°
        st.code("ğŸ§® ì˜¬í•´ ìµœì¢… íŒŒë¼ë¯¸í„°/ê·œëª¨", language="text")
        st.code(json.dumps({
            "beta_a": proj["a"], "beta_b": proj["b"],
            "q_select_this": proj["q_select_this"],
            "N(total_seats_this)": proj["total_seats_this"],
            "M_this(ì§€ì›ììˆ˜)": proj["M_this"],
            "ratio_this(ì…ë ¥/ìë™)": proj["ratio_this"],
        }, indent=2, ensure_ascii=False), language="json")

        # ì»· ë¶„í¬ ìš”ì•½/ìƒ˜í”Œ
        if len(sim["Ts"]) >= 10:
            g80, g50, g20 = np.quantile(sim["Ts"], [0.20, 0.50, 0.80])
        else:
            a, b = proj["a"], proj["b"]
            N = max(1, proj["total_seats_this"])
            samples = stats.beta.rvs(a, b, size=(2000, N)) * (hi - lo) + lo
            Ts_synth = samples.max(axis=1)
            g80, g50, g20 = np.quantile(Ts_synth, [0.20, 0.50, 0.80])

        st.code("ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ìš”ì•½(ìƒ˜í”Œ/ë¶„ìœ„ìˆ˜)", language="text")
        st.code(json.dumps({
            "g80": float(g80), "g50": float(g50), "g20": float(g20)
        }, indent=2, ensure_ascii=False), language="json")
        sample_list = [float(x) for x in np.round(sim["Ts"][:10], 3)]
        st.code("ìµœì¢…ì»· ìƒ˜í”Œ 10ê°œ:", language="text")
        st.code(json.dumps(sample_list, ensure_ascii=False), language="json")

    # ìµœì¢…ì»· ë¶„í¬ ë¶„ìœ„ìˆ˜ (ì‹œê°í™”ìš©)
    if len(sim["Ts"]) >= 10:
        g80, g50, g20 = np.quantile(sim["Ts"], [0.20, 0.50, 0.80])
    else:
        a, b = proj["a"], proj["b"]
        N = max(1, proj["total_seats_this"])
        samples = stats.beta.rvs(a, b, size=(2000, N)) * (hi - lo) + lo
        Ts_synth = samples.max(axis=1)
        g80, g50, g20 = np.quantile(Ts_synth, [0.20, 0.50, 0.80])

    # Risk ë²„í‚·(í•©ê²©í™•ë¥  p ê¸°ì¤€)
    p = sim['p_accept']
    if p >= 0.80: risk_bucket = "ì•ˆì •ê¶Œ"
    elif p >= 0.50: risk_bucket = "ì ì •ê¶Œ"
    elif p >= 0.20: risk_bucket = "ì†Œì‹ ê¶Œ"
    else: risk_bucket = "ìœ„í—˜ê¶Œ"

    # --------- ì¢Œ: ì…ì‹œí•™ë…„ë„ë³„ ì¶”ì„¸ ---------
    col1, col2 = st.columns(2)
    with col1:
        fig2, ax2 = plt.subplots(figsize=(6.6, 4.6))
        plot_map = {
            "50% (ì¤‘ìœ„ìˆ˜)": ("median", "fitted_median"),
            "70%": ("p70", "fitted_p70"),
            "ìµœì¢…ì»·": ("final_cut", "fitted_final"),
            "ìµœê³ ì ": ("best", "fitted_best"),
            "ìµœì´ˆí•© ìµœê³ ": ("init_best", "fitted_init_best"),
            "ìµœì´ˆí•© ìµœì €": ("init_worst", "fitted_init_worst"),
        }
        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

        series_handles = []
        for i, (label, (input_col, fitted_col)) in enumerate(plot_map.items()):
            if fitted_col in df_fit and df_fit[fitted_col].notnull().any():
                color = colors[i % len(colors)]
                line, = ax2.plot(
                    df_fit["year"], df_fit[fitted_col],
                    color=color, marker='o', linestyle='-', label=label, zorder=3
                )
                series_handles.append(line)
                if input_col in df and df[input_col].notnull().any():
                    ax2.scatter(
                        df["year"], df[input_col],
                        color=color, marker='x', s=80, linewidths=2, alpha=0.9, zorder=5
                    )

        if series_handles:
            leg_series = ax2.legend(handles=series_handles, loc='upper left', title='ì§€í‘œ', frameon=True)
            ax2.add_artist(leg_series)

        marker_legend = [
            Line2D([0], [0], color='gray', marker='o', linestyle='-', label='ëª¨ë¸ ì í•©ì¹˜'),
            Line2D([0], [0], color='gray', marker='x', linestyle='None', markersize=9, label='ì›ë³¸ ì…ë ¥ê°’'),
        ]
        ax2.legend(handles=marker_legend, loc='lower right', title='í‘œê¸°', frameon=True)

        ax2.set_title("ì…ì‹œí•™ë…„ë„ë³„ ì í•© ì§€í‘œ ì¶”ì„¸")
        ax2.set_xlabel("ì…ì‹œí•™ë…„ë„")
        ax2.set_ylabel("ë“±ê¸‰")
        ax2.invert_yaxis()
        ax2.grid(True, linestyle=':', alpha=0.6)

        years_ticks = sorted(pd.Series(df_fit["year"]).dropna().astype(int).unique().tolist())
        if years_ticks:
            ax2.set_xticks(years_ticks)
            ax2.set_xticklabels([str(y) for y in years_ticks])

        st.pyplot(fig2, use_container_width=True)

    # --------- ìš°: í•©ê²© ê°€ëŠ¥ì„± ë¶„ì„ ---------
    with col2:
        fig, ax = plt.subplots(figsize=(6.6, 4.6))
        lo, hi = grade_bounds

        # ë°°ê²½ êµ¬ê°„
        ax.axvspan(lo, g80,  alpha=0.12, color="#1f77b4", zorder=0)
        ax.axvspan(g80, g50, alpha=0.12, color="#2ca02c", zorder=0)
        ax.axvspan(g50, g20, alpha=0.12, color="#ffbf00", zorder=0)
        ax.axvspan(g20, hi,  alpha=0.12, color="#d62728", zorder=0)

        # ê²½ê³„ì„ 
        ax.axvline(g80, ls=":", lw=1, color="gray")
        ax.axvline(g50, ls=":", lw=1, color="gray")
        ax.axvline(g20, ls=":", lw=1, color="gray")

        # ìµœì¢…ì»· ì‹œë®¬ë ˆì´ì…˜ íˆìŠ¤í† ê·¸ë¨
        if len(sim["Ts"]) > 0:
            ax.hist(sim["Ts"], bins=30, density=True, alpha=0.40, label="ìµœì¢…ì»· ì‹œë®¬ë ˆì´ì…˜ ë¶„í¬")

        # ì§€ì›ì ì ìˆ˜ì„  & ë¦¬ìŠ¤í¬ ë¼ë²¨
        ax.axvline(applicant_grade, ls="--", lw=2, color="black", label=f"ì§€ì›ì ì ìˆ˜ = {applicant_grade:.2f}")
        ax.text(applicant_grade, ax.get_ylim()[1]*0.95, f"â–¶ {'ì•ˆì •ê¶Œ' if p>=0.8 else 'ì ì •ê¶Œ' if p>=0.5 else 'ì†Œì‹ ê¶Œ' if p>=0.2 else 'ìœ„í—˜ê¶Œ'}",
                ha="center", va="top",
                bbox=dict(boxstyle="round,pad=0.3", fc="yellow", ec="black", lw=1, alpha=0.8))

        # ì¤‘ì•™ê°’ ê°€ì´ë“œ
        ax.axvline(g50, ls=":", color="blue", label=f"ì˜ˆìƒ ìµœì¢…ì»· ì¤‘ì•™ê°’ â‰’ {g50:.2f}")

        ax.set_title("í•©ê²© ê°€ëŠ¥ì„± ë¶„ì„")
        ax.set_xlabel("ë‚´ì‹  ë“±ê¸‰ (ë‚®ì„ìˆ˜ë¡ ìš°ìˆ˜)")
        ax.set_ylabel("í™•ë¥  ë°€ë„")
        ax.set_xlim(lo, hi)
        ax.invert_xaxis()

        # ë²”ë¡€(ì°¨íŠ¸ìš©)ëŠ” ë“±ê¸‰ ê²½ê³„ê°’ í‘œê¸° ìœ ì§€
        zone_handles = [
            Patch(color="#1f77b4", alpha=0.35, label=f"ì•ˆì •ê¶Œ (â‰¤ {g80:.2f})"),
            Patch(color="#2ca02c", alpha=0.35, label=f"ì ì •ê¶Œ ({g80:.2f} ~ {g50:.2f})"),
            Patch(color="#ffbf00", alpha=0.35, label=f"ì†Œì‹ ê¶Œ ({g50:.2f} ~ {g20:.2f})"),
            Patch(color="#d62728", alpha=0.35, label=f"ìœ„í—˜ê¶Œ (â‰¥ {g20:.2f})"),
        ]
        handles, labels = ax.get_legend_handles_labels()
        ax.legend(handles=handles + zone_handles, loc="best")
        st.pyplot(fig, use_container_width=True)

    # --------- ìš”ì•½ ë©”íŠ¸ë¦­ ---------
    st.markdown("### ê²°ê³¼ ìš”ì•½")
    def _fmt_ci(ci_tuple):
        a, b = ci_tuple if isinstance(ci_tuple, (list, tuple)) and len(ci_tuple) == 2 else (np.nan, np.nan)
        if not (np.isfinite(a) and np.isfinite(b)): return "â€”"
        return f"{a*100:.1f}% ~ {b*100:.1f}%"

    c1, c2, c3 = st.columns(3)
    risk_help = (
        "êµ¬ê°„ ì •ì˜(í•©ê²©í™•ë¥  ê¸°ì¤€):\n"
        "- ì•ˆì •ê¶Œ: í•©ê²©í™•ë¥  â‰¥ 80%\n"
        "- ì ì •ê¶Œ: 50% â‰¤ í•©ê²©í™•ë¥  < 80%\n"
        "- ì†Œì‹ ê¶Œ: 20% â‰¤ í•©ê²©í™•ë¥  < 50%\n"
        "- ìœ„í—˜ê¶Œ: í•©ê²©í™•ë¥  < 20%"
    )
    st.metric(label="ì§€ì›ì ì ìˆ˜ ìœ„ì¹˜", value=("ì•ˆì •ê¶Œ" if p>=0.8 else "ì ì •ê¶Œ" if p>=0.5 else "ì†Œì‹ ê¶Œ" if p>=0.2 else "ìœ„í—˜ê¶Œ"),
              delta=f"{applicant_grade} ë“±ê¸‰", help=risk_help)
    c1.metric("ì˜ˆìƒ í•©ê²© í™•ë¥ ", f"{sim['p_accept']*100:.1f}%", help=f"90% ì‹ ë¢°êµ¬ê°„: {_fmt_ci(sim['p_accept_ci'])}")
    c2.metric("í•©ê²© ì‹œ ì˜ˆìƒ ìˆœìœ„(ìƒìœ„)", (f"{sim['p_pct']*100:.1f}%" if np.isfinite(sim['p_pct']) else "â€”"),
              help=f"90% CI: {_fmt_ci(sim['p_pct_ci'])}")
    c3.metric("ì˜¬í•´ ëª¨ì§‘ì •ì›", f"{proj['capacity_this']}ëª…",
              help=f"ì •ì› {proj['capacity_this']}ëª… + ì¶”ê°€ì¶©ì› {(extra_this_year if extra_this_year is not None else 'ìë™ ì¶”ì •')}")

    # ë³´ì¶© ì •ë³´
    is_ratio_known = proj.get("ratio_this") is not None
    is_extra_known = extra_this_year is not None
    if sim.get("mode") == "probabilistic":
        info_text = []
        if not is_ratio_known or not is_extra_known:
            info_text.append("ğŸ’¡ **ì˜¬í•´ ë¯¸ì…ë ¥ ì •ë³´ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì¶”ì •í•˜ì—¬ ë¶„ì„í–ˆìŠµë‹ˆë‹¤:**")
            if sim.get("forecasted_ratio_median") is not None:
                med, ci = sim["forecasted_ratio_median"], sim["forecasted_ratio_ci"]
                info_text.append(f"- **ê²½ìŸë¥ :** ì¤‘ì•™ê°’ **{med:.2f}:1** (90% CI: {ci[0]:.2f} ~ {ci[1]:.2f})")
            if sim.get("forecasted_extra_rate_median") is not None:
                med, ci = sim["forecasted_extra_rate_median"], sim["forecasted_extra_rate_ci"]
                info_text.append(f"- **ì¶©ì›ìœ¨:** ì¤‘ì•™ê°’ **{med:.1%}** (90% CI: {ci[0]:.1%} ~ {ci[1]:.1%})")
        else:
            info_text.append(f"ì˜¬í•´ ê²½ìŸë¥  **{proj['ratio_this']:.2f}:1** (ì§€ì›ì ì•½ {proj['M_this']}ëª…) ê¸°ì¤€ ë¶„ì„ì…ë‹ˆë‹¤.")
        if info_text:
            st.info("\n".join(info_text))
    elif sim.get("mode") == "fallback":
        st.warning("ê²½ìŸë¥ /ì¶©ì›ìœ¨ ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ **í´ë°± ëª¨ë“œ**(í•©ê²©ì ë¶„í¬ë§Œìœ¼ë¡œ ì¶”ì •)ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤. ë¶ˆí™•ì‹¤ì„±ì´ í½ë‹ˆë‹¤.")
    elif sim.get("mode") == "underfilled":
        st.info("ì§€ì›ìê°€ ì •ì›ì— ëª» ë¯¸ì¹˜ëŠ” **ë¯¸ë‹¬ ì‹œë‚˜ë¦¬ì˜¤(underfilled)**ë¡œ ê°„ì£¼í•˜ì—¬ ì»·ì´ ìƒë‹¨ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” í´ë°±ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.")

# ===================== ìƒë‹¨ íƒ€ì´í‹€/ì‚¬ì´ë“œë°” =====================
st.title("ğŸ“ ìˆ˜ì‹œ í•©ê²© ê°€ëŠ¥ì„± ì˜ˆì¸¡ê¸°")

with st.sidebar:
    st.header("ğŸ‘¤ ì§€ì›ì ì •ë³´")
    applicant_grade = st.number_input(
        "ë‚˜ì˜ ë‚´ì‹  ë“±ê¸‰", min_value=1.0, max_value=9.0, value=4.44, step=0.01,
        help="ë¶„ì„í•˜ê³  ì‹¶ì€ ë³¸ì¸ì˜ ë“±ê¸‰ì„ ì…ë ¥í•˜ì„¸ìš”."
    )

    st.header("âš™ï¸ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •")
    n_sims = st.slider(
        "ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", min_value=1000, max_value=10000, value=5000, step=500,
        help="ë†’ì„ìˆ˜ë¡ ì•ˆì •ì ì¸ ì¶”ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )

    use_app_dist_features = st.checkbox(
        "ì§€ì›ì ë¶„í¬ íŠ¹ì„±ë°˜ì˜", value=True,
        help="ì§€ì›ì ìµœê³ /í‰ê· /ìµœì €(app_*) ë°ì´í„°ë¥¼ í™œìš©í•´ ì§€ì›ì í’€ì˜ ë¶„í¬ í˜•íƒœ(ì™œë„ ë“±)ë¥¼ ë” ì •êµí•˜ê²Œ ì¶”ì •í•©ë‹ˆë‹¤. ê´€ë ¨ ë°ì´í„°ê°€ ì‹ ë¢°í•  ìˆ˜ ìˆì„ ë•Œ ìœ íš¨í•©ë‹ˆë‹¤."
    )

    # âœ… ë””ë²„ê·¸ ëª¨ë“œ (ë³µì›)
    debug_mode = st.checkbox(
        "ë””ë²„ê·¸ ëª¨ë“œ (ì¤‘ê°„ê°’ ì¶œë ¥)", value=False,
        help="ì „ì²˜ë¦¬/í”¼íŒ…/íˆ¬ì˜/ì‹œë®¬ë ˆì´ì…˜ì˜ í•µì‹¬ ì¤‘ê°„ê°’ì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤."
    )

# ---- ê¸°ë³¸ ë°ì´í„° ----
default_df = pd.DataFrame([
    {"year": 2023, "mean": 3.83, "median": None, "p70": None, "final_cut": 5.85, "best": 2.73,
     "capacity": 14, "extra": 8, "competition_ratio": 14.79,
     "app_best": 1.80, "app_mean": 4.25, "app_worst": 8.72,
     "init_best": 2.94, "init_mean": 3.67, "init_worst": 5.67},
    {"year": 2024, "mean": 4.12, "median": None, "p70": None, "final_cut": 5.29, "best": 3.05,
     "capacity": 6, "extra": 6, "competition_ratio": 22.17,
     "app_best": 1.90, "app_mean": 4.32, "app_worst": 7.52,
     "init_best": 1.90, "init_mean": 3.54, "init_worst": 4.86},
    {"year": 2025, "mean": 3.72, "median": None, "p70": None, "final_cut": 4.50, "best": 2.76,
     "capacity": 11, "extra": 5, "competition_ratio": 32.73,
     "app_best": 1.82, "app_mean": 3.96, "app_worst": 7.22,
     "init_best": 1.82, "init_mean": 3.49, "init_worst": 4.50},
], dtype=object)

# ---- ìµœì´ˆ ì„¸ì…˜ ì´ˆê¸°í™” ----
if 'init' not in st.session_state:
    st.session_state.department_name = "ê°€í†¨ë¦­ëŒ€ ë¯¸ë””ì–´ê¸°ìˆ ì½˜í…ì¸ í•™ê³¼ ì ì¬ëŠ¥ë ¥ìš°ìˆ˜ìì„œë¥˜"
    st.session_state.capacity_this = 6
    st.session_state.extra_this = 0
    st.session_state.ratio_this = 0.0
    # ğŸ†• ëª…ì‹œì  ì…ë ¥ ìƒíƒœ ì œì–´
    st.session_state.extra_inputted = False
    st.session_state.ratio_inputted = False
    st.session_state.df_editor = default_df.copy()
    st.session_state.init = True

# ===================== í”„ë¡œí•„ Pre-apply (ìœ„ì ¯ ìƒì„± ì „ 1íšŒ ì ìš©) =====================
def _apply_profile_payload(payload: dict, column_order):
    cur = payload.get("current_year_inputs", {}) if isinstance(payload, dict) else {}
    st.session_state.department_name = str(payload.get("department_name", "") or "")
    st.session_state.capacity_this   = int(cur.get("capacity", 1) or 1)
    st.session_state.extra_this      = int(cur.get("extra", 0) or 0)
    st.session_state.ratio_this      = float(cur.get("ratio", 0.0) or 0.0)

    # ğŸ†• ì…ë ¥ ìƒíƒœ ë³µì› (ê¸°ë³¸ê°’: ì…ë ¥ ì•ˆí•¨)
    st.session_state.extra_inputted = cur.get("extra_inputted", False)
    st.session_state.ratio_inputted = cur.get("ratio_inputted", False)

    hist = pd.DataFrame(payload.get("historical_data", []))
    st.session_state.df_editor = hist.reindex(columns=column_order)

if st.session_state.get("_PROFILE_TO_APPLY", None) is not None:
    try:
        _apply_profile_payload(st.session_state["_PROFILE_TO_APPLY"], COLUMN_ORDER)
        st.session_state["_PROFILE_TO_APPLY"] = None
        st.session_state["_UPLOAD_REV"] = st.session_state.get("_UPLOAD_REV", 0) + 1
    except Exception as e:
        st.session_state["_PROFILE_TO_APPLY"] = None
        st.session_state["_UPLOAD_REV"] = st.session_state.get("_UPLOAD_REV", 0) + 1
        st.session_state["_PROFILE_APPLY_ERROR"] = f"í”„ë¡œí•„ ì ìš© ì‹¤íŒ¨: {e}"

# ===================== ë³¸ë¬¸: í”„ë¡œí•„/í‘œ/íŒŒì¼ IO/ì‹¤í–‰ =====================
with st.container(border=True):
    
    st.markdown("##### ì˜¬í•´ ì…ì‹œ ì •ë³´")
   

    # ğŸ†• 2ì¤„ ë ˆì´ì•„ì›ƒ: 1ì¤„ì— í•™ê³¼ëª…ê³¼ ì •ì›, 2ì¤„ì— ì¶”ê°€ì¶©ì›, ì…ë ¥í•¨, ê²½ìŸë¥ , ì…ë ¥í•¨
    # 1ì¤„: í•™ê³¼ëª… | ì •ì›
    c1, c2 = st.columns([1, 1])
    department_name = c1.text_input("í•™ê³¼ëª…", key="department_name")
    capacity_this = c2.number_input("ì •ì›", min_value=1, step=1, key="capacity_this")
    
    # 2ì¤„: ì¶”ê°€ì¶©ì› | ì…ë ¥í•¨ | ê²½ìŸë¥  | ì…ë ¥í•¨
    c3, c4, c5, c6 = st.columns([1, 1, 1, 1])
    
    # ì¶”ê°€ì¶©ì›
    extra_this = c3.number_input(
        "ì¶”ê°€ì¶©ì›", 
        min_value=0, 
        step=1, 
        key="extra_this",
        disabled=not st.session_state.get("extra_inputted", False)
    )
    
    # ì¶”ê°€ì¶©ì› ì…ë ¥í•¨ ì²´í¬ë°•ìŠ¤
    extra_inputted = c4.checkbox(
        "ì…ë ¥í•¨", 
        value=st.session_state.get("extra_inputted", False),
        key="extra_inputted",
        help="ì²´í¬í•˜ë©´ ì¶”ê°€ì¶©ì› ê°’ì„ ì…ë ¥í•˜ê³ , ì²´í¬í•˜ì§€ ì•Šìœ¼ë©´ ìë™ ì¶”ì •ë©ë‹ˆë‹¤",
        on_change=lambda: _reset_value_on_uncheck("extra_inputted", "extra_this", 0)
    )
    
    # ê²½ìŸë¥ 
    ratio_this = c5.number_input(
        "ê²½ìŸë¥ ",
        min_value=0.0,
        step=0.1,
        key="ratio_this",
        disabled=not st.session_state.get("ratio_inputted", False)
    )
    
    # ê²½ìŸë¥  ì…ë ¥í•¨ ì²´í¬ë°•ìŠ¤
    ratio_inputted = c6.checkbox(
        "ì…ë ¥í•¨",
        value=st.session_state.get("ratio_inputted", False),
        key="ratio_inputted",
        help="ì²´í¬í•˜ë©´ ê²½ìŸë¥ ì„ ì…ë ¥í•˜ê³ , ì²´í¬í•˜ì§€ ì•Šìœ¼ë©´ ìë™ ì¶”ì •ë©ë‹ˆë‹¤",
        on_change=lambda: _reset_value_on_uncheck("ratio_inputted", "ratio_this", 0.0)
    )

    # ------ ê³¼ê±° ì…ì‹œ ê²°ê³¼ (í¼ìœ¼ë¡œ í¸ì§‘-ì ìš© ë¶„ë¦¬) ------
    st.markdown("##### ê³¼ê±° ì…ì‹œ ê²°ê³¼")
    st.caption("í‘œë¥¼ í¸ì§‘í•œ ë’¤, ì•„ë˜ â€˜í‘œ ë³€ê²½ ì ìš©â€™ì„ ëˆŒëŸ¬ ë°˜ì˜í•˜ì„¸ìš”.")

    column_config = {
        "year": st.column_config.NumberColumn("ì…ì‹œí•™ë…„ë„", min_value=2000, max_value=2100, step=1, format="%d"),
        "best": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì ìµœê³ ", step=0.01, format="%.2f"),
        "median": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì 50%", step=0.01, format="%.2f"),
        "p70": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì 70%", step=0.01, format="%.2f"),
        "final_cut": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì ìµœì €(ì»·)", step=0.01, format="%.2f"),
        "mean": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì í‰ê· ", step=0.01, format="%.2f"),
        "init_best": st.column_config.NumberColumn("ìµœì´ˆí•©ê²©ì ìµœê³ ", step=0.01, format="%.2f"),
        "init_worst": st.column_config.NumberColumn("ìµœì´ˆí•©ê²©ì ìµœì €", step=0.01, format="%.2f"),
        "init_mean": st.column_config.NumberColumn("ìµœì´ˆí•©ê²©ì í‰ê· ", step=0.01, format="%.2f"),
        "app_best": st.column_config.NumberColumn("ì§€ì›ì ìµœê³ ", step=0.01, format="%.2f"),
        "app_worst": st.column_config.NumberColumn("ì§€ì›ì ìµœì €", step=0.01, format="%.2f"),
        "app_mean": st.column_config.NumberColumn("ì§€ì›ì í‰ê· ", step=0.01, format="%.2f"),
        "capacity": st.column_config.NumberColumn("ì •ì›", min_value=0, step=1, format="%d"),
        "extra": st.column_config.NumberColumn("ì¶”ê°€ì¶©ì›", min_value=0, step=1, format="%d"),
        "competition_ratio": st.column_config.NumberColumn("ê²½ìŸë¥ ", min_value=0.0, step=0.01, format="%.2f"),
    }

    df_display = st.session_state.df_editor.reindex(columns=COLUMN_ORDER).rename(columns=COLUMN_CONFIG)

    with st.form("history_form", border=False):
        edited_df_display = st.data_editor(
            df_display,
            key="hist_editor",
            column_config=column_config,
            num_rows="dynamic",
            use_container_width=True,
            hide_index=True,
        )
        submitted = st.form_submit_button("âœ… í‘œ ë³€ê²½ ì ìš©", use_container_width=True)
        if submitted:
            try:
                st.session_state.df_editor = edited_df_display.rename(columns=REVERSE_COLUMN_MAP).reindex(columns=COLUMN_ORDER)
                st.success("í‘œ ë³€ê²½ ì‚¬í•­ì„ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"í‘œ ë³€ê²½ ë°˜ì˜ ì¤‘ ì˜¤ë¥˜: {e}")

    # ------ í”„ë¡œí•„ íŒŒì¼ ì €ì¥í•˜ê¸° / ë¶ˆëŸ¬ì˜¤ê¸° ------
    st.markdown("##### í”„ë¡œí•„ íŒŒì¼  ì €ì¥í•˜ê¸° / ë¶ˆëŸ¬ì˜¤ê¸°")
    lcol, rcol = st.columns([1,1], vertical_alignment="center")

    with lcol:
        data_to_save = {
            "department_name": st.session_state.get("department_name", ""),
            "current_year_inputs": {
                "capacity":     int(st.session_state.get("capacity_this", 0) or 0),
                "extra":        int(st.session_state.get("extra_this", 0) or 0),
                "ratio":        float(st.session_state.get("ratio_this", 0.0) or 0.0),
                # ğŸ†• ì…ë ¥ ìƒíƒœ ì •ë³´ ì €ì¥
                "extra_inputted": st.session_state.get("extra_inputted", False),
                "ratio_inputted": st.session_state.get("ratio_inputted", False),
            },
            "historical_data": st.session_state.df_editor.reindex(columns=COLUMN_ORDER).to_dict(orient="records"),
        }
        json_data = json.dumps(data_to_save, indent=2, ensure_ascii=False)
        safe_department_name = "".join([c for c in st.session_state.get("department_name","") if c.isalnum() or c in (' ', '-')]).rstrip()
        st.download_button(
            "ğŸ’¾ ì €ì¥í•˜ê¸° (JSON)", data=json_data,
            file_name=f'{safe_department_name or "profile"}_í”„ë¡œí•„.json',
            mime='application/json', use_container_width=True
        )

        if "_UPLOAD_REV" not in st.session_state:
            st.session_state["_UPLOAD_REV"] = 0

    with rcol:
        uc1, uc2 = st.columns([3,1], vertical_alignment="center")
        uploaded_file = uc1.file_uploader(
            "ë¶ˆëŸ¬ì˜¤ê¸° (JSON)", type="json",
            key=f"prof_uploader_{st.session_state['_UPLOAD_REV']}",
            help="íŒŒì¼ ì„ íƒ í›„ â€˜ì ìš©' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”."
        )
        apply_disabled = uploaded_file is None
        if uc2.button("ì ìš©", use_container_width=True, disabled=apply_disabled):
            if uploaded_file is None:
                st.warning("ë¨¼ì € JSON íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
            else:
                try:
                    payload = json.load(uploaded_file)
                    st.session_state["_PROFILE_TO_APPLY"] = payload
                    st.session_state["_UPLOAD_REV"] += 1
                    st.rerun()
                except Exception as e:
                    st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        if st.session_state.get("_PROFILE_APPLY_ERROR"):
            st.error(st.session_state.pop("_PROFILE_APPLY_ERROR"))

# ------ ì‹¤í–‰ ë²„íŠ¼ ------
if st.button("ğŸš€ ì˜ˆì¸¡ ì‹¤í–‰", type="primary", use_container_width=True):
    with st.spinner("ë°ì´í„° ë¶„ì„ ë° ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            np.random.seed(None)  # í•­ìƒ ë¹„ê³ ì •

            current_weights = BASE_WEIGHTS.copy()
            if use_app_dist_features:
                st.info("â„¹ï¸ ì˜µì…˜ í™œì„±: ì§€ì›ì ë¶„í¬ íŠ¹ì„±(app_*)ì„ ë°˜ì˜í•©ë‹ˆë‹¤.")
                current_weights.update({"app_mean": 0.3, "app_best": 0.3, "app_worst": 0.3})

            def to_py_type(v):
                if v is None: return None
                if isinstance(v, str) and v.strip() == "": return None
                if isinstance(v, (float, np.floating)) and pd.isna(v): return None
                try: return float(v)
                except (ValueError, TypeError): return None

            years_data = []
            for row in st.session_state.df_editor.to_dict(orient="records"):
                rec = {k: to_py_type(row.get(k)) for k in COLUMN_ORDER}
                if rec.get("year") is not None:
                    years_data.append(rec)

            run_pipeline(
                years_data=years_data,
                department_name=st.session_state.department_name,
                applicant_grade=float(applicant_grade),
                grade_bounds=GRADE_BOUNDS,
                capacity_this_year=int(st.session_state.capacity_this),
                # ğŸ†• ì…ë ¥ ìƒíƒœì— ë”°ë¥¸ ê°’ ì „ë‹¬
                extra_this_year=(int(st.session_state.extra_this) if st.session_state.get("extra_inputted", False) else None),
                ratio_this_year=(float(st.session_state.ratio_this) if st.session_state.get("ratio_inputted", False) else None),
                n_scenarios=int(n_sims),
                weights=current_weights,
                debug=bool(debug_mode)
            )
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e)
