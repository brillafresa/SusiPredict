# -*- coding: utf-8 -*-
# app.py
# ğŸ“ ìˆ˜ì‹œ í•©ê²© ê°€ëŠ¥ì„± ì˜ˆì¸¡ê¸° (Streamlit)
# v7.0 â€” Causal Forecasting (Predicting DNA, not outcomes)

import numpy as np
import pandas as pd
import math
import json
from typing import Dict, List, Tuple, Optional, NamedTuple

import matplotlib.pyplot as plt
from matplotlib import rcParams
from matplotlib.patches import Patch
from matplotlib.lines import Line2D
from scipy import optimize, stats
from scipy.special import betainc

import streamlit as st

# ===================== í˜ì´ì§€/ìŠ¤íƒ€ì¼ ì„¤ì • =====================
st.set_page_config(page_title="ìˆ˜ì‹œ í•©ê²© ê°€ëŠ¥ì„± ì˜ˆì¸¡ê¸°", layout="wide")

GRADE_BOUNDS = (1.0, 9.0)

# í•œê¸€ í°íŠ¸ ì„¤ì • (ë¡œì»¬ í°íŠ¸ ê°•ì œ ì§€ì •)
import os
from matplotlib.font_manager import FontProperties, findfont

def setup_korean_font():
    """í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ë¡œì»¬ í°íŠ¸ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."""
    try:
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ fonts í´ë”ì—ì„œ NanumGothic.ttf ì°¾ê¸°
        font_path = os.path.join(os.path.dirname(__file__), "fonts", "NanumGothic.ttf")
        
        if os.path.exists(font_path):
            # ë¡œì»¬ í°íŠ¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ê°•ì œë¡œ ì„¤ì •
            font_prop = FontProperties(fname=font_path)
            plt.rcParams["font.family"] = font_prop.get_name()
            return True
        else:
            # ë¡œì»¬ í°íŠ¸ê°€ ì—†ìœ¼ë©´ ì‹œìŠ¤í…œ í°íŠ¸ ì‹œë„
            font_candidates = ["Malgun Gothic", "NanumGothic", "AppleGothic", "Noto Sans CJK KR", "sans-serif"]
            for font_name in font_candidates:
                try:
                    found_font = findfont(font_name)
                    if found_font != "DejaVu Sans":
                        plt.rcParams["font.family"] = font_name
                        return True
                except Exception:
                    continue
            
            # ëª¨ë“  í°íŠ¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
            plt.rcParams["font.family"] = "sans-serif"
            return False
            
    except Exception as e:
        plt.rcParams["font.family"] = "sans-serif"
        return False

# í°íŠ¸ ì„¤ì • ì‹¤í–‰
setup_korean_font()
rcParams["axes.unicode_minus"] = False

# ê¸°ë³¸ ê°€ì¤‘ì¹˜
BASE_WEIGHTS = {
    "final_cut": 10.0, "best": 5.0, "median": 5.0, "mean": 4.0, "p70": 3.0,
    "init_mean": 2.0, "init_best": 2.0, "init_worst": 2.0,
    "app_mean": 0.0, "app_best": 0.0, "app_worst": 0.0,
}

# ---- ì»¬ëŸ¼/í‘œì‹œëª… ì •ì˜ ----
COLUMN_CONFIG = {
    "year": "ì…ì‹œí•™ë…„ë„",
    "best": "ìµœì¢…ë“±ë¡ì ìµœê³ ",
    "median": "ìµœì¢…ë“±ë¡ì 50%",
    "p70": "ìµœì¢…ë“±ë¡ì 70%",
    "final_cut": "ìµœì¢…ë“±ë¡ì ìµœì €(ì»·)",
    "mean": "ìµœì¢…ë“±ë¡ì í‰ê· ",
    "init_best": "ìµœì´ˆí•©ê²©ì ìµœê³ ",
    "init_worst": "ìµœì´ˆí•©ê²©ì ìµœì €",
    "init_mean": "ìµœì´ˆí•©ê²©ì í‰ê· ",
    "app_best": "ì§€ì›ì ìµœê³ ",
    "app_worst": "ì§€ì›ì ìµœì €",
    "app_mean": "ì§€ì›ì í‰ê· ",
    "capacity": "ì •ì›",
    "extra": "ì¶”ê°€ì¶©ì›",
    "competition_ratio": "ê²½ìŸë¥ ",
}
COLUMN_ORDER = [
    "year", "best", "median", "p70", "final_cut", "mean",
    "init_best", "init_worst", "init_mean",
    "app_best", "app_worst", "app_mean",
    "capacity", "extra", "competition_ratio"
]
REVERSE_COLUMN_MAP = {v: k for k, v in COLUMN_CONFIG.items()}

# ===================== ìˆ˜í•™ ìœ í‹¸/êµ¬ì¡° =====================
class QuantileTerm(NamedTuple):
    kind: str
    p: float
    value: float

class MeanTerm(NamedTuple):
    kind: str
    value: float
    q_trunc: Optional[float]

def _clip(x, lo, hi): return np.clip(x, lo, hi)
def _safe_ppf_p(p): return _clip(p, 1e-6, 1 - 1e-6)
def _beta_ppf_std(p, a, b): return stats.beta.ppf(_safe_ppf_p(p), a, b)
def _beta_quantile(p, a, b, lo, hi): return _beta_ppf_std(p, a, b) * (hi - lo) + lo
def _beta_cdf(x, a, b, lo, hi): return stats.beta.cdf(_clip((x - lo) / (hi - lo), 0.0, 1.0), a, b)


def _beta_trunc_mean_std(a, b, z_trunc):
    denominator = betainc(a, b, z_trunc)
    if denominator <= 1e-12:
        return z_trunc * 0.5
    numerator = (a / (a + b)) * betainc(a + 1, b, z_trunc)
    return numerator / denominator

def _admitted_quantile_from_underlying(p_cond, a, b, lo, hi, q_sel):
    return _beta_quantile(p_cond * q_sel, a, b, lo, hi)

def _is_bad(a, b):
    return not (np.isfinite(a) and np.isfinite(b) and 0.2 < a < 100.0 and 0.2 < b < 100.0)

# ğŸ†• ì²´í¬ë°•ìŠ¤ í•´ì œ ì‹œ ê°’ì„ ë¦¬ì…‹í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
def _reset_value_on_uncheck(checkbox_key: str, value_key: str, default_value):
    """ì²´í¬ë°•ìŠ¤ê°€ í•´ì œë˜ì—ˆì„ ë•Œ í•´ë‹¹ ê°’ í•„ë“œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ë¦¬ì…‹í•©ë‹ˆë‹¤."""
    if not st.session_state.get(checkbox_key, False):
        st.session_state[value_key] = default_value

def _solve_beta_two_quantiles(q1: QuantileTerm, q2: QuantileTerm, lo, hi, init_ab=(3.0, 6.0)):
    def objective(v):
        a, b = math.exp(v[0]), math.exp(v[1])
        e1 = _beta_quantile(q1.p, a, b, lo, hi) - q1.value
        e2 = _beta_quantile(q2.p, a, b, lo, hi) - q2.value
        return e1*e1 + e2*e2
    try:
        res = optimize.minimize(objective, np.log(np.array(init_ab)), method="Nelder-Mead")
        ab = np.exp(res.x)
        if not np.all(np.isfinite(ab)):
            return init_ab
        return float(ab[0]), float(ab[1])
    except Exception:
        return init_ab

def _get_stochastic_forecast(years: np.ndarray, values: np.ndarray, n_scenarios: int, min_val: float = 0.0, alpha: float = 0.6) -> np.ndarray:
    """
    'ìµœê·¼ ê°€ì¤‘ í‰ê· 'ì„ ì˜ˆì¸¡ì˜ ì¤‘ì‹¬ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ê³¼ê±°ì˜ ë³€ë™ì„±ì„ ë°˜ì˜í•˜ì—¬ í™•ë¥ ì ìœ¼ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    valid_mask = np.isfinite(years) & np.isfinite(values)
    years, values = years[valid_mask], values[valid_mask]

    if len(values) < 2: # ì˜ë¯¸ ìˆëŠ” í‰ê· /ë³€ë™ì„±ì„ ê³„ì‚°í•˜ë ¤ë©´ ìµœì†Œ 2ê°œì˜ ë°ì´í„° í•„ìš”
        return np.random.choice(values, n_scenarios, replace=True) if len(values) > 0 else np.array([])
    
    # 1. 'ìµœê·¼ ê°€ì¤‘ í‰ê· 'ìœ¼ë¡œ ì˜ˆì¸¡ì˜ ì¤‘ì‹¬ì ì„ ê³„ì‚°
    forecast_center = _predict_with_recency_weighted_average(years, values, alpha=alpha)

    # 2. ê³¼ê±°ì˜ ë³€ë™ì„±(ë‹¨ìˆœ í‰ê· ê³¼ì˜ ì°¨ì´)ì„ ê³„ì‚°
    residuals = values - np.mean(values)
    
    # 3. ì¤‘ì‹¬ì ê³¼ ë³€ë™ì„±ì„ ê²°í•©í•˜ì—¬ n_scenariosê°œì˜ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    scenarios = forecast_center + np.random.choice(residuals, n_scenarios, replace=True)
    
    return np.maximum(min_val, scenarios)

# ===================== ì „ì²˜ë¦¬/í”¼íŒ…/íˆ¬ì˜ =====================
def prepare_years(df_input: List[Dict]) -> pd.DataFrame:
    """ê³¼ê±° ë°ì´í„° ê°€ê³µ + ìœ íš¨ ê²½ìŸë¥  ë³´ì •(ì§€ì›ì í‰ê·  ê¸°ë°˜) + q_select ê³„ì‚°
       ê²½ìŸë¥  ì •ì˜: ratio = applicants / capacity
    """
    if not df_input:
        return pd.DataFrame()
    df_temp = pd.DataFrame(df_input)

    valid_app_means = df_temp['app_mean'].dropna()
    baseline_app_mean = valid_app_means.mean() if len(valid_app_means) >= 2 else None

    rows = []
    for r in df_input:
        cap = r.get("capacity", None)
        ext = r.get("extra", None)
        cap = int(cap) if cap is not None else None
        ext = int(ext) if ext is not None else 0
        total = (cap or 0) + (ext or 0)  # ìµœì¢… ì„ ë°œ ì¸ì› N

        ratio = r.get("competition_ratio", None)  # ratio = applicants / capacity
        applicants = r.get("applicants", None)
        if ratio is None and applicants is not None and cap:
            try:
                ratio = float(applicants) / float(cap) if cap > 0 else None
            except Exception:
                ratio = None

        effective_ratio = ratio
        if (ratio is not None) and (baseline_app_mean is not None) and pd.notnull(r.get("app_mean")):
            deviation = (r["app_mean"] - baseline_app_mean) / baseline_app_mean
            effective_ratio = ratio * (1 + np.clip(deviation, -0.3, 0.3))

        M = None
        if effective_ratio is not None and cap:
            M = float(effective_ratio) * float(cap)

        q_sel = min(1.0, float(total) / float(M)) if (M and M > 0) else None

        row_data = r.copy()
        row_data.update({
            "total_seats": total if total > 0 else None,      # N
            "competition_ratio": ratio,                        # ratio = applicants / capacity
            "effective_competition_ratio": effective_ratio,    # ë³´ì • ê²½ìŸë¥ 
            "q_select": q_sel,                                 # N/M
        })
        rows.append(row_data)

    return pd.DataFrame(rows).sort_values("year").reset_index(drop=True)

def _objective_function(params, quantile_terms, mean_terms, lo, hi, weights, return_details=False):
    a, b = math.exp(params[0]), math.exp(params[1])
    loss = 0.0
    details = {}
    for term in quantile_terms:
        pred = _beta_quantile(term.p, a, b, lo, hi)
        w = weights.get(term.kind, 1.0)
        if w > 0:
            err = w * (pred - term.value)**2
            loss += err
            details[term.kind] = err
    for term in mean_terms:
        w = weights.get(term.kind, 1.0)
        if w == 0:
            continue
        if term.q_trunc is None:
            pred = lo + (hi - lo) * (a / (a + b))
        else:
            z_trunc = _beta_ppf_std(term.q_trunc, a, b)
            mean_std = _beta_trunc_mean_std(a, b, z_trunc)
            pred = lo + (hi - lo) * mean_std
        err = w * (pred - term.value)**2
        loss += err
        details[term.kind] = err
    
    if return_details:
        return loss, details
    return loss

def _fit_underlying_from_competitive(row, lo, hi, weights):
    """ê²½ìŸë¥ /ì¶©ì› ì •ë³´ê°€ ìˆëŠ” ì—°ë„: ì „ì²´ ì§€ì›ìë¶„í¬(Beta) ì—­ì¶”ì •"""
    q_sel = row["q_select"]
    total, cap = row["total_seats"], row["capacity"]  # total=N, cap=ì •ì›
    eff_ratio = row.get("effective_competition_ratio", None)

    M = int(round(eff_ratio * cap)) if (eff_ratio is not None and cap) else None
    q_init = (cap / M) if (cap and M and M > 0) else None

    q_terms: List[QuantileTerm] = []
    m_terms: List[MeanTerm] = []

    if pd.notnull(row.get("median")):
        q_terms.append(QuantileTerm("median", 0.5 * q_sel, row["median"]))
    if pd.notnull(row.get("p70")):
        q_terms.append(QuantileTerm("p70", 0.7 * q_sel, row["p70"]))
    if pd.notnull(row.get("final_cut")):
        q_terms.append(QuantileTerm("final_cut", 1.0 * q_sel, row["final_cut"]))
    if pd.notnull(row.get("best")) and total:
        q_terms.append(QuantileTerm("best", (1/(total+1)) * q_sel, row["best"]))
    if pd.notnull(row.get("mean")):
        m_terms.append(MeanTerm("mean", row["mean"], q_sel))

    if q_init and cap:
        if pd.notnull(row.get("init_best")):
            q_terms.append(QuantileTerm("init_best", (1/(cap+1)) * q_init, row["init_best"]))
        if pd.notnull(row.get("init_worst")):
            q_terms.append(QuantileTerm("init_worst", (cap/(cap+1)) * q_init, row["init_worst"]))
        if pd.notnull(row.get("init_mean")):
            m_terms.append(MeanTerm("init_mean", row["init_mean"], q_init))

    if M:
        if pd.notnull(row.get("app_best")):
            q_terms.append(QuantileTerm("app_best", 1/(M+1), row["app_best"]))
        if pd.notnull(row.get("app_worst")):
            q_terms.append(QuantileTerm("app_worst", M/(M+1), row["app_worst"]))
        if pd.notnull(row.get("app_mean")):
            m_terms.append(MeanTerm("app_mean", row["app_mean"], None))

    if len(q_terms) < 2:
        return 3.0, 6.0, np.nan, {"M": M, "q_init": q_init, "terms": (q_terms, m_terms, lo, hi, weights)}

    q_terms.sort(key=lambda t: t.p)
    init_a, init_b = _solve_beta_two_quantiles(q_terms[0], q_terms[-1], lo, hi)

    res = optimize.minimize(
        _objective_function,
        np.log([init_a, init_b]),
        args=(q_terms, m_terms, lo, hi, weights),
        method="Nelder-Mead",
        options={"maxiter": 2500}
    )
    a, b = np.exp(res.x)
    if (not res.success) or _is_bad(a, b):
        return 3.0, 6.0, res.fun if hasattr(res, "fun") else np.nan, {"M": M, "q_init": q_init, "terms": (q_terms, m_terms, lo, hi, weights)}
    return float(a), float(b), float(res.fun), {"M": M, "q_init": q_init, "terms": (q_terms, m_terms, lo, hi, weights)}

def _fit_admitted_without_ratio(row, lo, hi, weights):
    """ê²½ìŸë¥  ì •ë³´ê°€ ì—†ëŠ” ì—°ë„: í•©ê²©ì ë¶„í¬ë¡œ ê°€ì •í•˜ì—¬ í”¼íŒ…(ê·¼ì‚¬)"""
    N, cap = row["total_seats"], row["capacity"]
    q_terms: List[QuantileTerm] = []
    m_terms: List[MeanTerm] = []

    if pd.notnull(row.get("median")):
        q_terms.append(QuantileTerm("median", 0.5, row["median"]))
    if pd.notnull(row.get("p70")):
        q_terms.append(QuantileTerm("p70", 0.7, row["p70"]))
    if pd.notnull(row.get("final_cut")) and N:
        q_terms.append(QuantileTerm("final_cut", N/(N+1), row["final_cut"]))
    if pd.notnull(row.get("best")) and N:
        q_terms.append(QuantileTerm("best", 1/(N+1), row["best"]))
    if pd.notnull(row.get("mean")):
        m_terms.append(MeanTerm("mean", row["mean"], None))

    if cap and N and N > 0:
        phi = cap / float(N)
        if pd.notnull(row.get("init_best")):
            q_terms.append(QuantileTerm("init_best", (1/(cap+1))*phi, row["init_best"]))
        if pd.notnull(row.get("init_worst")):
            q_terms.append(QuantileTerm("init_worst", (cap/(cap+1))*phi, row["init_worst"]))
        if pd.notnull(row.get("init_mean")):
            m_terms.append(MeanTerm("init_mean", row["init_mean"], phi))

    if len(q_terms) < 2:
        return 3.0, 6.0, np.nan, {}

    q_terms.sort(key=lambda t: t.p)
    init_a, init_b = _solve_beta_two_quantiles(q_terms[0], q_terms[-1], lo, hi)

    res = optimize.minimize(
        _objective_function,
        np.log([init_a, init_b]),
        args=(q_terms, m_terms, lo, hi, weights),
        method="Nelder-Mead",
        options={"maxiter": 2500}
    )
    a, b = np.exp(res.x)
    if (not res.success) or _is_bad(a, b):
        return 3.0, 6.0, res.fun if hasattr(res, "fun") else np.nan, {}
    return float(a), float(b), float(res.fun), {}

def fit_per_year_models(df, lo, hi, weights, loss_threshold: float = 2.0):
    """ì—°ë„ë³„ (a,b) í”¼íŒ… + ì£¼ìš” ì§€í‘œì˜ ì í•©ì¹˜ ê³„ì‚°
    [v8.0] 2ë‹¨ê³„ ì˜¤ë¥˜ ì²˜ë¦¬: 'ë‚˜ìœ ì í•©'ê³¼ 'ì™„ì „í•œ ì‹¤íŒ¨'ë¥¼ êµ¬ë¶„í•˜ì—¬ ì§€ëŠ¥ì ìœ¼ë¡œ ëŒ€ì²˜
    """
    cols = [ "year","beta_a","beta_b","model_type","fit_loss","fit_status","invalidated_col","q_select","total_seats","capacity", "fitted_median","fitted_p70","fitted_final","fitted_best","fitted_final_mean", "fitted_init_best","fitted_init_worst","fitted_init_mean", "fitted_app_best","fitted_app_worst","fitted_app_mean" ]
    outs = []

    for _, row in df.iterrows():
        row_dict = row.to_dict()
        fit_func = _fit_underlying_from_competitive if pd.notnull(row["q_select"]) else _fit_admitted_without_ratio

        # 1. 1ì°¨ í”¼íŒ… ì‹œë„
        a, b, loss, meta = fit_func(row_dict, lo, hi, weights)
        status, invalidated = 'SUCCESS', None
        is_hard_failure = (a == 3.0 and b == 6.0) # ìµœì í™”ê¸°ê°€ í•´ë¥¼ ëª» ì°¾ì€ ëª…ë°±í•œ ì‹¤íŒ¨

        # 2. 'ë‚˜ìœ ì í•©' ë˜ëŠ” 'ì™„ì „í•œ ì‹¤íŒ¨' ì‹œ ì¬ì‹œë„
        if is_hard_failure or loss > loss_threshold:
            loss_details = {}
            if pd.notnull(row["q_select"]) and 'terms' in meta:
                _, loss_details = _objective_function(np.log([a, b]), *meta['terms'], return_details=True)

            if loss_details:
                worst_offender = max(loss_details, key=loss_details.get, default=None)
                if worst_offender:
                    row_retry = row_dict.copy()
                    row_retry[worst_offender] = None
                    invalidated = worst_offender
                    
                    # 2ì°¨ í”¼íŒ… ì‹œë„
                    a, b, loss, meta = fit_func(row_retry, lo, hi, weights)
                    is_hard_failure_after_retry = (a == 3.0 and b == 6.0)
                    status = 'FAILURE' if is_hard_failure_after_retry else 'RETRY_SUCCESS'
                else: # ì˜¤ì°¨ ìœ ë°œ í•­ëª© íŠ¹ì • ë¶ˆê°€
                    status = 'FAILURE' if is_hard_failure else 'POOR_FIT_UNRESOLVED'
            else: # ê²½ìŸë¥  ì—†ëŠ” ëª¨ë“œì´ê±°ë‚˜ ìƒì„¸ ì˜¤ì°¨ ê³„ì‚° ë¶ˆê°€
                status = 'FAILURE' if is_hard_failure else 'POOR_FIT'

        if status == 'FAILURE':
            a, b = np.nan, np.nan # ìµœì¢… ì‹¤íŒ¨ ì‹œ beta ê°’ì€ NaNìœ¼ë¡œ ëª…ì‹œ

        # ê²°ê³¼ ê³„ì‚° (í”¼íŒ… ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
        q_sel = float(row.get("q_select", np.nan))
        med, p70, fin, bst, fm = [np.nan] * 5
        init_b, init_w, im = [np.nan] * 3
        app_b, app_w, app_m = [np.nan] * 3
        
        if pd.notnull(a): # í”¼íŒ…ì´ ìµœì¢… ì„±ê³µí•œ ê²½ìš°ì—ë§Œ ì í•©ì¹˜ ê³„ì‚°
            if pd.notnull(q_sel):
                total = int(row["total_seats"]) if row["total_seats"] else None
                cap = int(row["capacity"]) if row["capacity"] else None
                med = _admitted_quantile_from_underlying(0.5, a, b, lo, hi, q_sel)
                p70 = _admitted_quantile_from_underlying(0.7, a, b, lo, hi, q_sel)
                fin = _admitted_quantile_from_underlying(1.0, a, b, lo, hi, q_sel)
                bst = _admitted_quantile_from_underlying(1.0/(total+1.0), a, b, lo, hi, q_sel) if total else np.nan
                
                z = _beta_ppf_std(q_sel, a, b)
                fm = lo + (hi - lo) * _beta_trunc_mean_std(a, b, z)
                
                if cap and 'q_init' in meta and meta['q_init']:
                    q_init = meta['q_init']
                    init_b = _admitted_quantile_from_underlying(1.0/(cap+1.0), a, b, lo, hi, q_init)
                    init_w = _admitted_quantile_from_underlying(cap/(cap+1.0), a, b, lo, hi, q_init)
                    z0 = _beta_ppf_std(q_init, a, b)
                    im = lo + (hi - lo) * _beta_trunc_mean_std(a, b, z0)
                
                if 'M' in meta and meta['M']:
                    M = meta['M']
                    app_b = _beta_quantile(1.0/(M+1.0), a, b, lo, hi)
                    app_w = _beta_quantile(M/(M+1.0), a, b, lo, hi)
                    app_m = lo + (hi - lo) * (a/(a+b))
            else: # admitted-only ëª¨ë“œ
                N = int(row["total_seats"]) if row["total_seats"] else None
                cap = int(row["capacity"]) if row["capacity"] else None
                med = _beta_quantile(0.5, a, b, lo, hi)
                p70 = _beta_quantile(0.7, a, b, lo, hi)
                fin = _beta_quantile(N/(N+1.0), a, b, lo, hi) if N else np.nan
                bst = _beta_quantile(1.0/(N+1.0), a, b, lo, hi) if N else np.nan
                fm = lo + (hi - lo) * (a/(a+b))

                if cap and N and N > 0:
                    phi = cap / float(N)
                    init_b = _beta_quantile((1.0/(cap+1.0)) * phi, a, b, lo, hi)
                    init_w = _beta_quantile((cap/(cap+1.0)) * phi, a, b, lo, hi)
                    z_phi = _beta_ppf_std(phi, a, b)
                    im = lo + (hi - lo) * _beta_trunc_mean_std(a, b, z_phi)

        model_type = "underlying+trunc" if pd.notnull(q_sel) else "admitted-only"
        
        outs.append([
            row["year"], a, b, model_type, loss, status, invalidated,
            q_sel, row["total_seats"], row["capacity"],
            med, p70, fin, bst, fm,
            init_b, init_w, im, app_b, app_w, app_m
        ])

    return pd.DataFrame(outs, columns=cols).sort_values("year").reset_index(drop=True)

# ---- ìµœê·¼ì—°ë„ ê°€ì¤‘ íšŒê·€ë¡œ 1ë…„ í›„ ì§€í‘œ ì•µì»¤ ì˜ˆì¸¡ ----
def _predict_with_recency_weighted_average(years: np.ndarray, values: np.ndarray, alpha: float = 0.6) -> float:
    """
    ìµœì‹  ë°ì´í„°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ê°€ì¤‘ í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    alpha (ê°ì†Œ ê³„ìˆ˜): 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ëª¨ë“  ì—°ë„ë¥¼ ë¹„ìŠ·í•˜ê²Œ, 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìµœê·¼ ì—°ë„ë§Œ ê³ ë ¤í•©ë‹ˆë‹¤.
    """
    if len(values) == 0: 
        return np.nan
    
    # ì—°ë„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì ìš©
    sorted_indices = np.argsort(years)
    sorted_values = values[sorted_indices]
    
    # ê°€ì¥ ìµœê·¼ ë°ì´í„°ë¶€í„° alpha^0, alpha^1, alpha^2... ìˆœìœ¼ë¡œ ê°€ì¤‘ì¹˜ ìƒì„±
    weights = alpha ** np.arange(len(sorted_values))
    weights /= np.sum(weights) # ê°€ì¤‘ì¹˜ ì´í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”
    
    # ìµœì‹  ë°ì´í„°ê°€ ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë°›ë„ë¡ ê°’ì„ ë’¤ì§‘ì–´ì¤€ í›„ ê°€ì¤‘ í‰ê·  ê³„ì‚°
    weighted_avg = np.sum(sorted_values[::-1] * weights)
    return float(weighted_avg)

def project_current_year(
    df, df_fit, lo, hi,
    capacity_this_year, extra_this_year, ratio_this_year, weights
):
    """
    << í•µì‹¬ ë¡œì§ ë³€ê²½ (v7.0) >>
    'ê²°ê³¼'ê°€ ì•„ë‹Œ 'ì›ì¸'ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    1. ê³¼ê±° ë°ì´í„°ë¡œë¶€í„° ê° ì—°ë„ì˜ ì§€ì›ì ë¶„í¬ 'DNA' (beta_a, beta_b)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (fit_per_year_modelsì—ì„œ ìˆ˜í–‰)
    2. ì´ 'DNA'ì˜ ì¶”ì„¸ë¥¼ ì˜ˆì¸¡í•˜ì—¬, ì˜¬í•´ì˜ ì§€ì›ì ë¶„í¬ DNA(a_proj, b_proj)ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    3. ì´ë ‡ê²Œ ì˜ˆì¸¡ëœ DNAë¥¼ ìµœì¢… ê²°ê³¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    years = df_fit["year"].values.astype(float)
    current_year = years.max() + 1.0 if len(years) > 0 else 2026
    
    # 1. 'DNA' (beta_a, beta_b) ì˜ˆì¸¡
    successful_fits = df_fit[df_fit['fit_status'] != 'FAILURE']
    s_a = successful_fits[['year', 'beta_a']].dropna()
    s_b = successful_fits[['year', 'beta_b']].dropna()
    
    a_proj = _predict_with_recency_weighted_average(s_a["year"].values, s_a["beta_a"].values, alpha=0.6)
    b_proj = _predict_with_recency_weighted_average(s_b["year"].values, s_b["beta_b"].values, alpha=0.6)

    # ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ ê°€ì¥ ìµœê·¼ ê°’ìœ¼ë¡œ í´ë°±
    if pd.isna(a_proj) or pd.isna(b_proj):
        if not s_a.empty: a_proj = s_a["beta_a"].iloc[-1]
        if not s_b.empty: b_proj = s_b["beta_b"].iloc[-1]
    
    # ê·¸ë˜ë„ ê°’ì´ ì—†ìœ¼ë©´ (ë°ì´í„°ê°€ ì „í˜€ ì—†ìœ¼ë©´) ê¸°ë³¸ê°’ìœ¼ë¡œ í´ë°±
    if pd.isna(a_proj) or pd.isna(b_proj) or _is_bad(a_proj, b_proj):
        a_proj, b_proj = 3.0, 6.0
    
    # 2. ì˜¬í•´ í™˜ê²½(N, M, q_select)ì— ëŒ€í•œ ëŒ€í‘œê°’ ê³„ì‚° (ë””ë²„ê·¸ ë° í‘œì‹œìš©)
    cap = int(capacity_this_year or 0)
    total_seats_base = cap + (int(extra_this_year) if extra_this_year is not None else 0)
    ratio = ratio_this_year if ratio_this_year and ratio_this_year > 0 else None
    
    ratio_for_display = ratio
    if ratio_for_display is None:
        historical = df["competition_ratio"].dropna().values
        ratio_for_display = np.median(historical) if len(historical) > 0 else None

    M = int(round(ratio_for_display * cap)) if (ratio_for_display and cap > 0) else None
    q_sel = (min(1.0, total_seats_base / M) if (M and M > 0) else None)
    q_init = (cap / float(M)) if (cap and M and M > 0) else None

    return {
        "a": float(a_proj), "b": float(b_proj),
        "model_type": "causal_forecast",
        "q_select_this": q_sel,
        "total_seats_this": total_seats_base, "capacity_this": cap,
        "ratio_this": ratio, "M_this": M, "q_init_this": q_init
    }

# ===================== ì‹œë®¬ë ˆì´ì…˜ =====================
def simulate_acceptance(
    proj, df, applicant_grade, lo, hi,
    capacity_this_year: int,
    extra_this_year: Optional[int],
    ratio_this_year: Optional[float],
    n_scenarios=5000
):
    a, b = proj["a"], proj["b"]
    is_ratio_known = ratio_this_year is not None and ratio_this_year > 0.0
    is_extra_known = extra_this_year is not None

    years = df["year"].values.astype(float)
    current_year = years.max() + 1.0 if len(years) > 0 else 2026

    extra_ratios = np.array([])

    if is_ratio_known:
        ratios = np.full(n_scenarios, float(ratio_this_year))
    else:
        ratios = _get_stochastic_forecast(
            years, df["competition_ratio"].values, n_scenarios, min_val=0.5
        )

    if is_extra_known:
        extras = np.full(n_scenarios, int(extra_this_year))
    else:
        with np.errstate(divide='ignore', invalid='ignore'):
            cap_series = pd.to_numeric(df["capacity"], errors="coerce").astype(float)
            extra_series = pd.to_numeric(df["extra"], errors="coerce").astype(float)
            extra_ratio_series = np.where(
                (cap_series > 0) & np.isfinite(cap_series),
                np.nan_to_num(extra_series / cap_series, nan=0.0),
                np.nan
            )
        extra_ratios = _get_stochastic_forecast(
            years, extra_ratio_series, n_scenarios, min_val=0.0
        )
        extras = np.round(np.nan_to_num(extra_ratios, nan=0.0) * capacity_this_year).astype(int)

    N_scenarios = capacity_this_year + extras                        # N
    M_scenarios = np.round(ratios * capacity_this_year).astype(int)  # M = ratio * capacity

    valid_mask = (N_scenarios > 0) & (M_scenarios >= N_scenarios)
    if not np.any(valid_mask):
        Ts = _beta_quantile(0.999, a, b, lo, hi) * np.ones(n_scenarios)
        accepted = (Ts >= applicant_grade)
        k, n = int(np.sum(accepted)), int(len(accepted))
        from scipy.stats import beta as _beta
        p_accept = k / n if n > 0 else np.nan
        p_accept_ci = tuple(_beta.ppf([0.05, 0.95], k + 0.5, (n - k) + 0.5)) if n > 0 else (np.nan, np.nan)
        return {"mode":"underfilled","Ts":Ts,"p_accept":p_accept,"p_accept_ci":p_accept_ci,
                "p_pct":np.nan,"p_pct_ci":(np.nan,np.nan)}

    N_scenarios = N_scenarios[valid_mask]
    M_scenarios = M_scenarios[valid_mask]

    U_samples = stats.beta.rvs(N_scenarios, M_scenarios - N_scenarios + 1)
    Ts = _beta_quantile(U_samples, a, b, lo, hi)

    accepted_mask = (Ts >= applicant_grade)
    k, n = int(np.sum(accepted_mask)), int(len(accepted_mask))
    from scipy.stats import beta as _beta
    p_accept = k / n if n > 0 else np.nan
    p_accept_ci = tuple(_beta.ppf([0.05, 0.95], k + 0.5, (n - k) + 0.5)) if n > 0 else (np.nan, np.nan)

    Fg = _beta_cdf(applicant_grade, a, b, lo, hi)
    if k > 0:
        ranks = np.clip(Fg / np.maximum(U_samples[accepted_mask], 1e-9), 0.0, 1.0)
        p_pct = float(np.mean(ranks))
        p_pct_ci = tuple(np.quantile(ranks, [0.05, 0.95]))
    else:
        p_pct, p_pct_ci = np.nan, (np.nan, np.nan)

    out = {
        "mode": "probabilistic",
        "Ts": Ts[np.isfinite(Ts)],
        "p_accept": p_accept,
        "p_accept_ci": p_accept_ci,
        "p_pct": p_pct,
        "p_pct_ci": p_pct_ci,
    }
    if ratio_this_year is None and len(ratios) > 0:
        out["forecasted_ratio_median"] = float(np.median(ratios))
        out["forecasted_ratio_ci"] = tuple(np.quantile(ratios, [0.05, 0.95]))
    if extra_this_year is None and len(extra_ratios) > 0:
        out["forecasted_extra_rate_median"] = float(np.median(extra_ratios))
        out["forecasted_extra_rate_ci"] = tuple(np.quantile(extra_ratios, [0.05, 0.95]))
    return out

# ===================== íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ & ì‹œê°í™” =====================
def run_pipeline(
    years_data, department_name, applicant_grade,
    grade_bounds=(1.0, 9.0),
    capacity_this_year=None, extra_this_year=None,
    ratio_this_year=None,
    n_scenarios=5000, weights=BASE_WEIGHTS, debug=False
):
    lo, hi = grade_bounds

    df = prepare_years(years_data)
    df_fit = fit_per_year_models(df, lo, hi, weights)
    
    # ìµœì¢… ì‹¤íŒ¨ ê°ì§€ ë° ì‹¤í–‰ ì¤‘ë‹¨
    if not df_fit.empty:
        last_year_status = df_fit.iloc[-1]['fit_status']
        if last_year_status == 'FAILURE':
            last_year = int(df_fit.iloc[-1]['year'])
            st.error(f"âŒ **ì˜ˆì¸¡ ì‹¤íŒ¨:** {last_year}í•™ë…„ë„ ë°ì´í„°ì˜ ë‚´ë¶€ ì¼ê´€ì„±ì´ ë‚®ì•„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ì—°ë„ì˜ ì…ë ¥ê°’ì„ í™•ì¸í•˜ê±°ë‚˜, 'ê³¼ê±° ì…ì‹œ ê²°ê³¼' í‘œì—ì„œ í•´ë‹¹ í–‰ì„ ì‚­ì œí•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            st.stop()
    
    proj = project_current_year(
        df, df_fit, lo, hi,
        capacity_this_year, extra_this_year,
        ratio_this_year, weights
    )
    sim = simulate_acceptance(
        proj, df, applicant_grade, lo, hi,
        capacity_this_year=int(capacity_this_year),
        extra_this_year=int(extra_this_year) if extra_this_year is not None else None,
        ratio_this_year=proj.get("ratio_this"),
        n_scenarios=n_scenarios
    )

    # ---------- ë””ë²„ê·¸ íŒ¨ë„ ----------
    if debug:
        st.markdown("### ğŸ§© ë””ë²„ê·¸ íŒ¨ë„")

        # ì „ì²˜ë¦¬ í•µì‹¬ ì§€í‘œ
        dbg_pre = pd.DataFrame({
            "year": df["year"],
            "capacity": df["capacity"],
            "extra": df["extra"],
            "ratio(raw)": df["competition_ratio"],
            "ratio(effective)": df["effective_competition_ratio"],
            "total_seats(N)": df["total_seats"],
            "q_select(N/M)": df["q_select"],
            "M(=ratio*capacity)": np.where(
                pd.notnull(df["effective_competition_ratio"]) & pd.notnull(df["capacity"]),
                df["effective_competition_ratio"] * df["capacity"], np.nan
            ),
        })
        st.code("ğŸ§© ì „ì²˜ë¦¬ ê²°ê³¼ (q_select Â· ëª¨ì§‘/ì§€ì› ê·œëª¨)", language="text")
        st.dataframe(dbg_pre, use_container_width=True)

        # í”¼íŒ… ê²°ê³¼(beta_a, beta_b ì¤‘ì‹¬)
        st.code("ğŸ§ª ì—°ë„ë³„ í”¼íŒ… ê²°ê³¼ (beta_a, beta_b)", language="text")
        st.dataframe(df_fit[["year","beta_a","beta_b","model_type","fit_loss"]], use_container_width=True)

        # ì˜¬í•´ íˆ¬ì˜ íŒŒë¼ë¯¸í„°
        st.code("ğŸ§® ì˜¬í•´ ìµœì¢… íŒŒë¼ë¯¸í„°/ê·œëª¨", language="text")
        st.code(json.dumps({k:v for k,v in proj.items()}, indent=2, ensure_ascii=False), language="json")

        # ì»· ë¶„í¬ ìš”ì•½/ìƒ˜í”Œ
        if len(sim["Ts"]) >= 10:
            g80, g50, g20 = np.quantile(sim["Ts"], [0.20, 0.50, 0.80])
        else:
            a, b = proj["a"], proj["b"]
            N = max(1, proj["total_seats_this"])
            samples = stats.beta.rvs(a, b, size=(2000, N)) * (hi - lo) + lo
            Ts_synth = samples.max(axis=1)
            g80, g50, g20 = np.quantile(Ts_synth, [0.20, 0.50, 0.80])

        st.code("ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ìš”ì•½(ìƒ˜í”Œ/ë¶„ìœ„ìˆ˜)", language="text")
        st.code(json.dumps({
            "g80": float(g80), "g50": float(g50), "g20": float(g20)
        }, indent=2, ensure_ascii=False), language="json")
        sample_list = [float(x) for x in np.round(sim["Ts"][:10], 3)]
        st.code("ìµœì¢…ì»· ìƒ˜í”Œ 10ê°œ:", language="text")
        st.code(json.dumps(sample_list, ensure_ascii=False), language="json")

    # ìµœì¢…ì»· ë¶„í¬ ë¶„ìœ„ìˆ˜ (ì‹œê°í™”ìš©)
    if len(sim["Ts"]) >= 10:
        g80, g50, g20 = np.quantile(sim["Ts"], [0.20, 0.50, 0.80])
    else:
        a, b = proj["a"], proj["b"]
        N = max(1, proj["total_seats_this"])
        samples = stats.beta.rvs(a, b, size=(2000, N)) * (hi - lo) + lo
        Ts_synth = samples.max(axis=1)
        g80, g50, g20 = np.quantile(Ts_synth, [0.20, 0.50, 0.80])

    # Risk ë²„í‚·(í•©ê²©í™•ë¥  p ê¸°ì¤€)
    p = sim['p_accept']
    if p >= 0.80: risk_bucket = "ì•ˆì •ê¶Œ"
    elif p >= 0.50: risk_bucket = "ì ì •ê¶Œ"
    elif p >= 0.20: risk_bucket = "ì†Œì‹ ê¶Œ"
    else: risk_bucket = "ìœ„í—˜ê¶Œ"

    # --------- ì¢Œ: ì…ì‹œí•™ë…„ë„ë³„ ì¶”ì„¸ ---------
    col1, col2 = st.columns(2)
    with col1:
        fig2, ax2 = plt.subplots(figsize=(6.6, 4.6))
        plot_map = {
            "50% (ì¤‘ìœ„ìˆ˜)": ("median", "fitted_median"),
            "70%": ("p70", "fitted_p70"),
            "ìµœì¢…ì»·": ("final_cut", "fitted_final"),
            "ìµœê³ ì ": ("best", "fitted_best"),
            "ìµœì´ˆí•© ìµœê³ ": ("init_best", "fitted_init_best"),
            "ìµœì´ˆí•© ìµœì €": ("init_worst", "fitted_init_worst"),
        }
        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

        series_handles = []
        for i, (label, (input_col, fitted_col)) in enumerate(plot_map.items()):
            if fitted_col in df_fit and df_fit[fitted_col].notnull().any():
                color = colors[i % len(colors)]
                line, = ax2.plot(
                    df_fit["year"], df_fit[fitted_col],
                    color=color, marker='o', linestyle='-', label=label, zorder=3
                )
                series_handles.append(line)
                if input_col in df and df[input_col].notnull().any():
                    ax2.scatter(
                        df["year"], df[input_col],
                        color=color, marker='x', s=80, linewidths=2, alpha=0.9, zorder=5
                    )

        if series_handles:
            leg_series = ax2.legend(handles=series_handles, loc='upper left', title='ì§€í‘œ', frameon=True)
            ax2.add_artist(leg_series)

        marker_legend = [
            Line2D([0], [0], color='gray', marker='o', linestyle='-', label='ëª¨ë¸ ì í•©ì¹˜'),
            Line2D([0], [0], color='gray', marker='x', linestyle='None', markersize=9, label='ì›ë³¸ ì…ë ¥ê°’'),
        ]
        ax2.legend(handles=marker_legend, loc='lower right', title='í‘œê¸°', frameon=True)

        ax2.set_title("ì…ì‹œí•™ë…„ë„ë³„ ì í•© ì§€í‘œ ì¶”ì„¸")
        ax2.set_xlabel("ì…ì‹œí•™ë…„ë„")
        ax2.set_ylabel("ë“±ê¸‰")
        ax2.invert_yaxis()
        ax2.grid(True, linestyle=':', alpha=0.6)

        years_ticks = sorted(pd.Series(df_fit["year"]).dropna().astype(int).unique().tolist())
        if years_ticks:
            ax2.set_xticks(years_ticks)
            ax2.set_xticklabels([str(y) for y in years_ticks])

        st.pyplot(fig2, use_container_width=True)

    # --------- ìš°: í•©ê²© ê°€ëŠ¥ì„± ë¶„ì„ ---------
    with col2:
        fig, ax = plt.subplots(figsize=(6.6, 4.6))
        lo, hi = grade_bounds

        # ë°°ê²½ êµ¬ê°„
        ax.axvspan(lo, g80,  alpha=0.12, color="#1f77b4", zorder=0)
        ax.axvspan(g80, g50, alpha=0.12, color="#2ca02c", zorder=0)
        ax.axvspan(g50, g20, alpha=0.12, color="#ffbf00", zorder=0)
        ax.axvspan(g20, hi,  alpha=0.12, color="#d62728", zorder=0)

        # ê²½ê³„ì„ 
        ax.axvline(g80, ls=":", lw=1, color="gray")
        ax.axvline(g50, ls=":", lw=1, color="gray")
        ax.axvline(g20, ls=":", lw=1, color="gray")

        # ìµœì¢…ì»· ì‹œë®¬ë ˆì´ì…˜ íˆìŠ¤í† ê·¸ë¨
        if len(sim["Ts"]) > 0:
            ax.hist(sim["Ts"], bins=30, density=True, alpha=0.40, label="ìµœì¢…ì»· ì‹œë®¬ë ˆì´ì…˜ ë¶„í¬")

        # ì§€ì›ì ì ìˆ˜ì„  & ë¦¬ìŠ¤í¬ ë¼ë²¨
        ax.axvline(applicant_grade, ls="--", lw=2, color="black", label=f"ì§€ì›ì ì ìˆ˜ = {applicant_grade:.2f}")
        ax.text(applicant_grade, ax.get_ylim()[1]*0.95, f"â–¶ {'ì•ˆì •ê¶Œ' if p>=0.8 else 'ì ì •ê¶Œ' if p>=0.5 else 'ì†Œì‹ ê¶Œ' if p>=0.2 else 'ìœ„í—˜ê¶Œ'}",
                ha="center", va="top",
                bbox=dict(boxstyle="round,pad=0.3", fc="yellow", ec="black", lw=1, alpha=0.8))

        # ì¤‘ì•™ê°’ ê°€ì´ë“œ
        ax.axvline(g50, ls=":", color="blue", label=f"ì˜ˆìƒ ìµœì¢…ì»· ì¤‘ì•™ê°’ â‰’ {g50:.2f}")

        ax.set_title("í•©ê²© ê°€ëŠ¥ì„± ë¶„ì„")
        ax.set_xlabel("ë‚´ì‹  ë“±ê¸‰ (ë‚®ì„ìˆ˜ë¡ ìš°ìˆ˜)")
        ax.set_ylabel("í™•ë¥  ë°€ë„")
        ax.set_xlim(lo, hi)
        ax.invert_xaxis()

        # ë²”ë¡€(ì°¨íŠ¸ìš©)ëŠ” ë“±ê¸‰ ê²½ê³„ê°’ í‘œê¸° ìœ ì§€
        zone_handles = [
            Patch(color="#1f77b4", alpha=0.35, label=f"ì•ˆì •ê¶Œ (â‰¤ {g80:.2f})"),
            Patch(color="#2ca02c", alpha=0.35, label=f"ì ì •ê¶Œ ({g80:.2f} ~ {g50:.2f})"),
            Patch(color="#ffbf00", alpha=0.35, label=f"ì†Œì‹ ê¶Œ ({g50:.2f} ~ {g20:.2f})"),
            Patch(color="#d62728", alpha=0.35, label=f"ìœ„í—˜ê¶Œ (â‰¥ {g20:.2f})"),
        ]
        handles, labels = ax.get_legend_handles_labels()
        ax.legend(handles=handles + zone_handles, loc="best")
        st.pyplot(fig, use_container_width=True)

    # --------- ìš”ì•½ ë©”íŠ¸ë¦­ ---------
    st.markdown("### ê²°ê³¼ ìš”ì•½")
    def _fmt_ci(ci_tuple):
        a, b = ci_tuple if isinstance(ci_tuple, (list, tuple)) and len(ci_tuple) == 2 else (np.nan, np.nan)
        if not (np.isfinite(a) and np.isfinite(b)): return "â€”"
        return f"{a*100:.1f}% ~ {b*100:.1f}%"

    c1, c2, c3 = st.columns(3)
    risk_help = (
        "êµ¬ê°„ ì •ì˜(í•©ê²©í™•ë¥  ê¸°ì¤€):\n"
        "- ì•ˆì •ê¶Œ: í•©ê²©í™•ë¥  â‰¥ 80%\n"
        "- ì ì •ê¶Œ: 50% â‰¤ í•©ê²©í™•ë¥  < 80%\n"
        "- ì†Œì‹ ê¶Œ: 20% â‰¤ í•©ê²©í™•ë¥  < 50%\n"
        "- ìœ„í—˜ê¶Œ: í•©ê²©í™•ë¥  < 20%"
    )
    st.metric(label="ì§€ì›ì ì ìˆ˜ ìœ„ì¹˜", value=("ì•ˆì •ê¶Œ" if p>=0.8 else "ì ì •ê¶Œ" if p>=0.5 else "ì†Œì‹ ê¶Œ" if p>=0.2 else "ìœ„í—˜ê¶Œ"),
              delta=f"{applicant_grade} ë“±ê¸‰", help=risk_help)
    c1.metric("ì˜ˆìƒ í•©ê²© í™•ë¥ ", f"{sim['p_accept']*100:.1f}%", help=f"90% ì‹ ë¢°êµ¬ê°„: {_fmt_ci(sim['p_accept_ci'])}")
    c2.metric("í•©ê²© ì‹œ ì˜ˆìƒ ìˆœìœ„(ìƒìœ„)", (f"{sim['p_pct']*100:.1f}%" if np.isfinite(sim['p_pct']) else "â€”"),
              help=f"90% CI: {_fmt_ci(sim['p_pct_ci'])}")
    c3.metric("ì˜¬í•´ ëª¨ì§‘ì •ì›", f"{proj['capacity_this']}ëª…",
              help=f"ì •ì› {proj['capacity_this']}ëª… + ì¶”ê°€ì¶©ì› {(extra_this_year if extra_this_year is not None else 'ìë™ ì¶”ì •')}")

    # ë³´ì¶© ì •ë³´
    is_ratio_known = proj.get("ratio_this") is not None
    is_extra_known = extra_this_year is not None
    if sim.get("mode") == "probabilistic":
        info_text = []
        if not is_ratio_known or not is_extra_known:
            info_text.append("ğŸ’¡ **ì˜¬í•´ ë¯¸ì…ë ¥ ì •ë³´ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì¶”ì •í•˜ì—¬ ë¶„ì„í–ˆìŠµë‹ˆë‹¤:**")
            if sim.get("forecasted_ratio_median") is not None:
                med, ci = sim["forecasted_ratio_median"], sim["forecasted_ratio_ci"]
                info_text.append(f"- **ê²½ìŸë¥ :** ì¤‘ì•™ê°’ **{med:.2f}:1** (90% CI: {ci[0]:.2f} ~ {ci[1]:.2f})")
            if sim.get("forecasted_extra_rate_median") is not None:
                med, ci = sim["forecasted_extra_rate_median"], sim["forecasted_extra_rate_ci"]
                info_text.append(f"- **ì¶©ì›ìœ¨:** ì¤‘ì•™ê°’ **{med:.1%}** (90% CI: {ci[0]:.1%} ~ {ci[1]:.1%})")
        else:
            info_text.append(f"ì˜¬í•´ ê²½ìŸë¥  **{proj['ratio_this']:.2f}:1** (ì§€ì›ì ì•½ {proj['M_this']}ëª…) ê¸°ì¤€ ë¶„ì„ì…ë‹ˆë‹¤.")
        if info_text:
            st.info("\n".join(info_text))
    elif sim.get("mode") == "fallback":
        st.warning("ê²½ìŸë¥ /ì¶©ì›ìœ¨ ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ **í´ë°± ëª¨ë“œ**(í•©ê²©ì ë¶„í¬ë§Œìœ¼ë¡œ ì¶”ì •)ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤. ë¶ˆí™•ì‹¤ì„±ì´ í½ë‹ˆë‹¤.")
    elif sim.get("mode") == "underfilled":
        st.info("ì§€ì›ìê°€ ì •ì›ì— ëª» ë¯¸ì¹˜ëŠ” **ë¯¸ë‹¬ ì‹œë‚˜ë¦¬ì˜¤(underfilled)**ë¡œ ê°„ì£¼í•˜ì—¬ ì»·ì´ ìƒë‹¨ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” í´ë°±ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.")

    # ì¬ì‹œë„ ì„±ê³µ ì •ë³´ ì¶”ê°€
    retry_success_df = df_fit[df_fit['fit_status'] == 'RETRY_SUCCESS']
    if not retry_success_df.empty:
        retry_notes = []
        for _, row in retry_success_df.iterrows():
            col_kor = {
                'median': 'ì¤‘ìœ„ìˆ˜', 'p70': '70%', 'final_cut': 'ìµœì¢…ì»·', 'best': 'ìµœê³ ì ',
                'init_best': 'ìµœì´ˆí•© ìµœê³ ì ', 'init_worst': 'ìµœì´ˆí•© ìµœì €ì ', 'init_mean': 'ìµœì´ˆí•© í‰ê· ',
                'app_best': 'ì§€ì›ì ìµœê³ ì ', 'app_worst': 'ì§€ì›ì ìµœì €ì ', 'app_mean': 'ì§€ì›ì í‰ê· '
            }.get(row['invalidated_col'], row['invalidated_col'])
            retry_notes.append(f"{int(row['year'])}í•™ë…„ë„ì˜ '{col_kor}'")
        
        st.warning(f"âš ï¸ **ë°ì´í„° ë³´ì • ì•Œë¦¼:** ì¼ë¶€ ì—°ë„ ë°ì´í„°ì˜ ì¼ê´€ì„±ì´ ë‚®ì•„ ë‹¤ìŒ í•­ëª©ì„ ì œì™¸í•˜ê³  ë¶„ì„í–ˆìŠµë‹ˆë‹¤: {', '.join(retry_notes)}")

# ===================== ìƒë‹¨ íƒ€ì´í‹€/ì‚¬ì´ë“œë°” =====================
st.title("ğŸ“ ìˆ˜ì‹œ í•©ê²© ê°€ëŠ¥ì„± ì˜ˆì¸¡ê¸°")

with st.sidebar:
    st.header("ğŸ‘¤ ì§€ì›ì ì •ë³´")
    applicant_grade = st.number_input(
        "ë‚˜ì˜ ë‚´ì‹  ë“±ê¸‰", min_value=1.0, max_value=9.0, value=4.44, step=0.01,
        help="ë¶„ì„í•˜ê³  ì‹¶ì€ ë³¸ì¸ì˜ ë“±ê¸‰ì„ ì…ë ¥í•˜ì„¸ìš”."
    )

    st.header("âš™ï¸ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •")
    n_sims = st.slider(
        "ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", min_value=1000, max_value=10000, value=5000, step=500,
        help="ë†’ì„ìˆ˜ë¡ ì•ˆì •ì ì¸ ì¶”ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )

    use_app_dist_features = st.checkbox(
        "ì§€ì›ì ë¶„í¬ íŠ¹ì„±ë°˜ì˜", value=True,
        help="ì§€ì›ì ìµœê³ /í‰ê· /ìµœì €(app_*) ë°ì´í„°ë¥¼ í™œìš©í•´ ì§€ì›ì í’€ì˜ ë¶„í¬ í˜•íƒœ(ì™œë„ ë“±)ë¥¼ ë” ì •êµí•˜ê²Œ ì¶”ì •í•©ë‹ˆë‹¤. ê´€ë ¨ ë°ì´í„°ê°€ ì‹ ë¢°í•  ìˆ˜ ìˆì„ ë•Œ ìœ íš¨í•©ë‹ˆë‹¤."
    )

    # âœ… ë””ë²„ê·¸ ëª¨ë“œ (ë³µì›)
    debug_mode = st.checkbox(
        "ë””ë²„ê·¸ ëª¨ë“œ (ì¤‘ê°„ê°’ ì¶œë ¥)", value=False,
        help="ì „ì²˜ë¦¬/í”¼íŒ…/íˆ¬ì˜/ì‹œë®¬ë ˆì´ì…˜ì˜ í•µì‹¬ ì¤‘ê°„ê°’ì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤."
    )

# ---- ê¸°ë³¸ ë°ì´í„° ----
default_df = pd.DataFrame([
    {"year": 2023, "mean": 3.83, "median": None, "p70": None, "final_cut": 5.85, "best": 2.73,
     "capacity": 14, "extra": 8, "competition_ratio": 14.79,
     "app_best": 1.80, "app_mean": 4.25, "app_worst": 8.72,
     "init_best": 2.94, "init_mean": 3.67, "init_worst": 5.67},
    {"year": 2024, "mean": 4.12, "median": None, "p70": None, "final_cut": 5.29, "best": 3.05,
     "capacity": 6, "extra": 6, "competition_ratio": 22.17,
     "app_best": 1.90, "app_mean": 4.32, "app_worst": 7.52,
     "init_best": 1.90, "init_mean": 3.54, "init_worst": 4.86},
    {"year": 2025, "mean": 3.72, "median": None, "p70": None, "final_cut": 4.50, "best": 2.76,
     "capacity": 11, "extra": 5, "competition_ratio": 32.73,
     "app_best": 1.82, "app_mean": 3.96, "app_worst": 7.22,
     "init_best": 1.82, "init_mean": 3.49, "init_worst": 4.50},
], dtype=object)

# ---- ìµœì´ˆ ì„¸ì…˜ ì´ˆê¸°í™” ----
if 'init' not in st.session_state:
    st.session_state.department_name = "ë™í•´êµ­ì œëŒ€ ë¯¸ë˜ë„ì‹œê³µí•™ê³¼ ì°½ì˜ìœµí•©ì¸ì¬ì „í˜•"
    st.session_state.capacity_this = 9
    st.session_state.extra_this = 0
    st.session_state.ratio_this = 0.0
    # ğŸ†• ëª…ì‹œì  ì…ë ¥ ìƒíƒœ ì œì–´
    st.session_state.extra_inputted = False
    st.session_state.ratio_inputted = False
    st.session_state.df_editor = default_df.copy()
    st.session_state.init = True

# ===================== í”„ë¡œí•„ Pre-apply (ìœ„ì ¯ ìƒì„± ì „ 1íšŒ ì ìš©) =====================
def _apply_profile_payload(payload: dict, column_order):
    cur = payload.get("current_year_inputs", {}) if isinstance(payload, dict) else {}
    st.session_state.department_name = str(payload.get("department_name", "") or "")
    st.session_state.capacity_this   = int(cur.get("capacity", 1) or 1)
    st.session_state.extra_this      = int(cur.get("extra", 0) or 0)
    st.session_state.ratio_this      = float(cur.get("ratio", 0.0) or 0.0)

    # ğŸ†• ì…ë ¥ ìƒíƒœ ë³µì› (ê¸°ë³¸ê°’: ì…ë ¥ ì•ˆí•¨)
    st.session_state.extra_inputted = cur.get("extra_inputted", False)
    st.session_state.ratio_inputted = cur.get("ratio_inputted", False)

    hist = pd.DataFrame(payload.get("historical_data", []))
    st.session_state.df_editor = hist.reindex(columns=column_order)

if st.session_state.get("_PROFILE_TO_APPLY", None) is not None:
    try:
        _apply_profile_payload(st.session_state["_PROFILE_TO_APPLY"], COLUMN_ORDER)
        st.session_state["_PROFILE_TO_APPLY"] = None
        st.session_state["_UPLOAD_REV"] = st.session_state.get("_UPLOAD_REV", 0) + 1
    except Exception as e:
        st.session_state["_PROFILE_TO_APPLY"] = None
        st.session_state["_UPLOAD_REV"] = st.session_state.get("_UPLOAD_REV", 0) + 1
        st.session_state["_PROFILE_APPLY_ERROR"] = f"í”„ë¡œí•„ ì ìš© ì‹¤íŒ¨: {e}"

# ===================== ë³¸ë¬¸: í”„ë¡œí•„/í‘œ/íŒŒì¼ IO/ì‹¤í–‰ =====================
with st.container(border=True):
    
    st.markdown("##### ğŸ“ í•™ê³¼ í”„ë¡œí•„")
    c1, c2 = st.columns([2,1])
    department_name = c1.text_input("í•™ê³¼ëª…", key="department_name")
    capacity_this = c2.number_input("ì •ì›", min_value=1, step=1, key="capacity_this")
    
    c3, c4, c5, c6 = st.columns([2,1,2,1])
    extra_this = c3.number_input(
        "ì¶”ê°€ì¶©ì›", 
        min_value=0, 
        step=1, 
        key="extra_this",
        disabled=not st.session_state.get("extra_inputted", False)
    )
    
    c4.checkbox(
        "ì…ë ¥í•¨", 
        value=st.session_state.get("extra_inputted", False),
        key="extra_inputted",
        help="ì²´í¬í•˜ë©´ ì¶”ê°€ì¶©ì› ê°’ì„ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•˜ê³ , ì²´í¬ í•´ì œ ì‹œ ìë™ ì¶”ì •ë©ë‹ˆë‹¤.",
        on_change=lambda: _reset_value_on_uncheck("extra_inputted", "extra_this", 0)
    )
    
    ratio_this = c5.number_input(
        "ê²½ìŸë¥ ",
        min_value=0.0,
        step=0.1,
        key="ratio_this",
        disabled=not st.session_state.get("ratio_inputted", False)
    )
    
    c6.checkbox(
        "ì…ë ¥í•¨",
        value=st.session_state.get("ratio_inputted", False),
        key="ratio_inputted",
        help="ì²´í¬í•˜ë©´ ê²½ìŸë¥ ì„ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•˜ê³ , ì²´í¬ í•´ì œ ì‹œ ìë™ ì¶”ì •ë©ë‹ˆë‹¤.",
        on_change=lambda: _reset_value_on_uncheck("ratio_inputted", "ratio_this", 0.0)
    )

    # ------ ê³¼ê±° ì…ì‹œ ê²°ê³¼ (í¼ìœ¼ë¡œ í¸ì§‘-ì ìš© ë¶„ë¦¬) ------
    st.markdown("##### ê³¼ê±° ì…ì‹œ ê²°ê³¼")
    st.caption("í‘œë¥¼ í¸ì§‘í•œ ë’¤, ì•„ë˜ â€˜í‘œ ë³€ê²½ ì ìš©â€™ì„ ëˆŒëŸ¬ ë°˜ì˜í•˜ì„¸ìš”.")

    column_config = {
        "year": st.column_config.NumberColumn("ì…ì‹œí•™ë…„ë„", min_value=2000, max_value=2100, step=1, format="%d"),
        "best": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì ìµœê³ ", step=0.01, format="%.2f"),
        "median": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì 50%", step=0.01, format="%.2f"),
        "p70": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì 70%", step=0.01, format="%.2f"),
        "final_cut": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì ìµœì €(ì»·)", step=0.01, format="%.2f"),
        "mean": st.column_config.NumberColumn("ìµœì¢…ë“±ë¡ì í‰ê· ", step=0.01, format="%.2f"),
        "init_best": st.column_config.NumberColumn("ìµœì´ˆí•©ê²©ì ìµœê³ ", step=0.01, format="%.2f"),
        "init_worst": st.column_config.NumberColumn("ìµœì´ˆí•©ê²©ì ìµœì €", step=0.01, format="%.2f"),
        "init_mean": st.column_config.NumberColumn("ìµœì´ˆí•©ê²©ì í‰ê· ", step=0.01, format="%.2f"),
        "app_best": st.column_config.NumberColumn("ì§€ì›ì ìµœê³ ", step=0.01, format="%.2f"),
        "app_worst": st.column_config.NumberColumn("ì§€ì›ì ìµœì €", step=0.01, format="%.2f"),
        "app_mean": st.column_config.NumberColumn("ì§€ì›ì í‰ê· ", step=0.01, format="%.2f"),
        "capacity": st.column_config.NumberColumn("ì •ì›", min_value=0, step=1, format="%d"),
        "extra": st.column_config.NumberColumn("ì¶”ê°€ì¶©ì›", min_value=0, step=1, format="%d"),
        "competition_ratio": st.column_config.NumberColumn("ê²½ìŸë¥ ", min_value=0.0, step=0.01, format="%.2f"),
    }

    df_display = st.session_state.df_editor.reindex(columns=COLUMN_ORDER).rename(columns=COLUMN_CONFIG)

    with st.form("history_form", border=False):
        edited_df_display = st.data_editor(
            df_display,
            key="hist_editor",
            column_config=column_config,
            num_rows="dynamic",
            use_container_width=True,
            hide_index=True,
        )
        submitted = st.form_submit_button("âœ… í‘œ ë³€ê²½ ì ìš©", use_container_width=True)
        if submitted:
            try:
                st.session_state.df_editor = edited_df_display.rename(columns=REVERSE_COLUMN_MAP).reindex(columns=COLUMN_ORDER)
                st.success("í‘œ ë³€ê²½ ì‚¬í•­ì„ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"í‘œ ë³€ê²½ ë°˜ì˜ ì¤‘ ì˜¤ë¥˜: {e}")

    st.markdown("###### **í”„ë¡œí•„ íŒŒì¼ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°**")
    lcol, rcol = st.columns([1,3])

    with lcol:
        data_to_save = {
            "department_name": st.session_state.get("department_name", ""),
            "current_year_inputs": {
                "capacity":     int(st.session_state.get("capacity_this", 0) or 0),
                "extra":        int(st.session_state.get("extra_this", 0) or 0),
                "ratio":        float(st.session_state.get("ratio_this", 0.0) or 0.0),
                # ğŸ†• ì…ë ¥ ìƒíƒœ ì •ë³´ ì €ì¥
                "extra_inputted": st.session_state.get("extra_inputted", False),
                "ratio_inputted": st.session_state.get("ratio_inputted", False),
            },
            "historical_data": st.session_state.df_editor.reindex(columns=COLUMN_ORDER).to_dict(orient="records"),
        }
        json_data = json.dumps(data_to_save, indent=2, ensure_ascii=False)
        safe_department_name = "".join([c for c in st.session_state.get("department_name","") if c.isalnum() or c in (' ', '-')]).rstrip()
        st.download_button(
            "ğŸ’¾ ì €ì¥", data=json_data,
            file_name=f'{safe_department_name or "profile"}_í”„ë¡œí•„.json',
            mime='application/json', use_container_width=True
        )

        if "_UPLOAD_REV" not in st.session_state:
            st.session_state["_UPLOAD_REV"] = 0

    with rcol:
        uc1, uc2 = st.columns([3,1], vertical_alignment="center")
        uploaded_file = uc1.file_uploader(
            "ë¶ˆëŸ¬ì˜¤ê¸° (JSON)", type="json",
            key=f"prof_uploader_{st.session_state['_UPLOAD_REV']}",
            help="íŒŒì¼ ì„ íƒ í›„ â€˜ì ìš©' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”."
        )
        apply_disabled = uploaded_file is None
        if uc2.button("ì ìš©", use_container_width=True, disabled=apply_disabled):
            if uploaded_file is None:
                st.warning("ë¨¼ì € JSON íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
            else:
                try:
                    payload = json.load(uploaded_file)
                    st.session_state["_PROFILE_TO_APPLY"] = payload
                    st.session_state["_UPLOAD_REV"] += 1
                    st.rerun()
                except Exception as e:
                    st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        if st.session_state.get("_PROFILE_APPLY_ERROR"):
            st.error(st.session_state.pop("_PROFILE_APPLY_ERROR"))

# ------ ì‹¤í–‰ ë²„íŠ¼ ------
if st.button("ğŸš€ ì˜ˆì¸¡ ì‹¤í–‰", type="primary", use_container_width=True):
    with st.spinner("ë°ì´í„° ë¶„ì„ ë° ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            np.random.seed(None)  # í•­ìƒ ë¹„ê³ ì •

            current_weights = BASE_WEIGHTS.copy()
            if use_app_dist_features:
                st.info("â„¹ï¸ ì˜µì…˜ í™œì„±: ì§€ì›ì ë¶„í¬ íŠ¹ì„±(app_*)ì„ ë°˜ì˜í•©ë‹ˆë‹¤.")
                current_weights.update({"app_mean": 0.3, "app_best": 0.3, "app_worst": 0.3})

            def to_py_type(v):
                if v is None or (isinstance(v, str) and v.strip() == "") or pd.isna(v): return None
                try: return float(v)
                except (ValueError, TypeError): return None

            years_data = []
            for row in st.session_state.df_editor.to_dict(orient="records"):
                rec = {k: to_py_type(row.get(k)) for k in COLUMN_ORDER}
                if rec.get("year") is not None:
                    years_data.append(rec)

            run_pipeline(
                years_data=years_data,
                department_name=st.session_state.department_name,
                applicant_grade=float(applicant_grade),
                grade_bounds=GRADE_BOUNDS,
                capacity_this_year=int(st.session_state.capacity_this),
                extra_this_year=(int(st.session_state.extra_this) if st.session_state.get("extra_inputted", False) else None),
                ratio_this_year=(float(st.session_state.ratio_this) if st.session_state.get("ratio_inputted", False) else None),
                n_scenarios=int(n_sims),
                weights=current_weights,
                debug=bool(debug_mode)
            )
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e)
